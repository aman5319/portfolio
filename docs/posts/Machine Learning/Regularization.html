<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aman Pandey">
<meta name="dcterms.date" content="2023-03-20">
<meta name="description" content="Different ways to increase the model’s prediction power using different regularization Techniques">

<title>Aman’s Blog - Improve Model’s Prediction power using Regularization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../posts/Machine Learning/Weight_Initializer.html" rel="next">
<link href="../../posts/Machine Learning/metrics.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Aman’s Blog - Improve Model’s Prediction power using Regularization">
<meta property="og:description" content="Different ways to increase the model’s prediction power using different regularization Techniques">
<meta property="og:image" content="https://aman5319.github.io/portfolio/posts/Machine Learning/images/dropout.gif">
<meta property="og:site-name" content="Aman's Blog">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Aman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target=""><i class="bi bi-file-person" role="img">
</i> 
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://drive.google.com/drive/folders/1pTPR0vPX1UoQYfyvQLu8Pn-Wc6hqrjGf?usp=sharing" rel="" target="_blank"><i class="bi bi-file-pdf" role="img">
</i> 
 <span class="menu-text">Resume</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/aman5319" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aman5319/" rel="" target="_blank"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Posts</li><li class="breadcrumb-item"><a href="../../posts/Machine Learning/Attention.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../../posts/Machine Learning/Regularization.html">Improve Model’s Prediction power using Regularization</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Improve Model’s Prediction power using Regularization</h1>
                  <div>
        <div class="description">
          Different ways to increase the model’s prediction power using different regularization Techniques
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep-learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Aman Pandey </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 20, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Computer Vision</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Computer Vision/convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolution and Common architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Computer Vision/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Different types of Attentions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/data_model_manage_prod.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data and Model Management | Model Monitoring and Logging.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics for Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Regularization.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Improve Model’s Prediction power using Regularization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Weight_Initializer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Weight Intialization</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">NLP</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/linguistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linguistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/nlp_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NLP Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/rnn_lstm_gru.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RNN Models</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Optimization/optimisers_in_dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Optimizers in - Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/big_data_processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Big Data Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/functional_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Functional Programming capabilites of python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/parallel_processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallelism and Concurrency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/profiling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Memory and Time Profiling</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#regularization" id="toc-regularization" class="nav-link active" data-scroll-target="#regularization">Regularization</a>
  <ul class="collapse">
  <li><a href="#l1l2-regularizers" id="toc-l1l2-regularizers" class="nav-link" data-scroll-target="#l1l2-regularizers">L1/L2 Regularizers</a>
  <ul class="collapse">
  <li><a href="#l2-regularization" id="toc-l2-regularization" class="nav-link" data-scroll-target="#l2-regularization">L2 regularization</a></li>
  <li><a href="#l1-regularization" id="toc-l1-regularization" class="nav-link" data-scroll-target="#l1-regularization">L1 regularization</a></li>
  </ul></li>
  <li><a href="#dropout" id="toc-dropout" class="nav-link" data-scroll-target="#dropout">Dropout</a></li>
  <li><a href="#label-smoothing" id="toc-label-smoothing" class="nav-link" data-scroll-target="#label-smoothing">Label Smoothing</a></li>
  </ul></li>
  <li><a href="#data-augmentation" id="toc-data-augmentation" class="nav-link" data-scroll-target="#data-augmentation">Data Augmentation</a>
  <ul class="collapse">
  <li><a href="#what-is-data-augmentation" id="toc-what-is-data-augmentation" class="nav-link" data-scroll-target="#what-is-data-augmentation">what is Data Augmentation ?</a></li>
  <li><a href="#why-do-we-need-image-augmentation" id="toc-why-do-we-need-image-augmentation" class="nav-link" data-scroll-target="#why-do-we-need-image-augmentation">Why do we Need Image Augmentation</a></li>
  <li><a href="#what-is-the-solution-to-all-above-problems" id="toc-what-is-the-solution-to-all-above-problems" class="nav-link" data-scroll-target="#what-is-the-solution-to-all-above-problems">What is the solution to all above problems</a></li>
  <li><a href="#do-we-need-augmentation-if-training-data-set-is-huge" id="toc-do-we-need-augmentation-if-training-data-set-is-huge" class="nav-link" data-scroll-target="#do-we-need-augmentation-if-training-data-set-is-huge">Do we need Augmentation If training data set is huge?</a></li>
  <li><a href="#data-augmentation-in-pytorch-and-visualization" id="toc-data-augmentation-in-pytorch-and-visualization" class="nav-link" data-scroll-target="#data-augmentation-in-pytorch-and-visualization">Data Augmentation in Pytorch and visualization</a></li>
  <li><a href="#lets-see-something-different" id="toc-lets-see-something-different" class="nav-link" data-scroll-target="#lets-see-something-different">Let’s see something different</a></li>
  <li><a href="#early-stopping" id="toc-early-stopping" class="nav-link" data-scroll-target="#early-stopping">Early Stopping</a></li>
  <li><a href="#weight-clipping-and-gradient-clipping" id="toc-weight-clipping-and-gradient-clipping" class="nav-link" data-scroll-target="#weight-clipping-and-gradient-clipping">Weight Clipping and Gradient Clipping</a></li>
  <li><a href="#pruning" id="toc-pruning" class="nav-link" data-scroll-target="#pruning">Pruning</a></li>
  </ul></li>
  <li><a href="#normalization-and-standardization" id="toc-normalization-and-standardization" class="nav-link" data-scroll-target="#normalization-and-standardization">Normalization and Standardization</a>
  <ul class="collapse">
  <li><a href="#batch-normalization" id="toc-batch-normalization" class="nav-link" data-scroll-target="#batch-normalization">Batch Normalization</a></li>
  <li><a href="#weight-norm" id="toc-weight-norm" class="nav-link" data-scroll-target="#weight-norm">Weight Norm</a></li>
  <li><a href="#layer-norm" id="toc-layer-norm" class="nav-link" data-scroll-target="#layer-norm">Layer Norm</a></li>
  <li><a href="#thank-you." id="toc-thank-you." class="nav-link" data-scroll-target="#thank-you.">Thank you.</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.dev/aman5319/portfolio/blob/main/posts/Machine Learning/Regularization.ipynb" class="toc-action">Edit this page</a></p><p><a href="https://github.com/aman5319/portfolio/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="regularization" class="level1">
<h1>Regularization</h1>
<p>A central problem in machine learning is how to make an algorithm that will perform well not just on the training data, but also on new inputs. The great <code>OverFitting Problem</code>.</p>
<p>Many strategies used in machine learning are explicitly designed to reduce the test error, possibly at the expense of increased training error. These strategies are known collectively as regularization.</p>
<p>One of the easiet to say but harder to do things is to increase the amount of training data.</p>
<p>Regularization increases training error but reduces generalization error hence more no of epochs are needed to get the desired result. Regularization helps to reduce overfitting of the model.</p>
<p>There are many regularization techniques used some but extra term in objective function and some but extra constraint on the model.</p>
<ol type="1">
<li>L1/L2 regularizers</li>
<li>DropOut</li>
<li>Label Smoothing</li>
<li>Data Augmentation</li>
<li>Early Stopping</li>
<li>Weight Clipping and Gradient Clipping</li>
<li>Pruning</li>
<li>Normalization</li>
</ol>
<section id="l1l2-regularizers" class="level2">
<h2 class="anchored" data-anchor-id="l1l2-regularizers">L1/L2 Regularizers</h2>
<p>L1 and L2 regularizers are some time known as weight decay.</p>
<p>L1 Regularization works by adding an l1 norm to the cost function.</p>
<p><span class="math display">\[
L1\ Norm :
||X||_1 = \sum_i |x_i|
\]</span> L2 Regularization works by adding an l2 norm to the cost function.</p>
<p><span class="math display">\[
L2\ Norm :
||X||_2 = \sqrt {\sum_i |x_i^2|}
\]</span></p>
<p>The idea behind l1 and l2 norm is smaller weight generalizes the model better so both of these norm perform some kind of weight decay.</p>
<section id="l2-regularization" class="level3">
<h3 class="anchored" data-anchor-id="l2-regularization">L2 regularization</h3>
<p><span class="math display">\[
    C = any\ loss\ function  + \frac{\lambda}{2n}\sum w^2
\]</span></p>
<p>Here λ is a regularization parameter and n is the size of training data w is the weight.we are adding a sum of squares of all weights to the cost function which is scaled by λ/2n where λ &gt; 0.</p>
<p>The intitution behind the l2 reguarization is to make it so the network prefers to learn small weights. Large weights will only be allowed if they considerably improve the first part of the cost function.</p>
<p>Put another way, regularization can be viewed as a way of compromising between finding small weights and minimizing the original cost function.</p>
<p>The relative importance of the two elements of the compromise depends on the value of λ: when λ is small we prefer to minimize the original cost function, but when λ is large we prefer small weights.</p>
<p>Updating weight formulae while backprop <span class="math display">\[
w = w - {lr} \frac{\partial C}{\partial w} - \frac {{lr} \lambda} {n} w
\]</span></p>
<p><span class="math display">\[
w = \left( 1 - \frac{{lr}\lambda } {n} \right) w - {lr} \frac{\partial C}{\partial w}
\]</span></p>
<p>Here <span class="math display">\[
\left( 1 - \frac{{lr} \lambda } {n} \right)
\]</span> is the rescaling factor for weights or the weight decay factor.For very small λ value it is allowing big weights and if λ value is big it is penealizing the weights.</p>
<p>Why is this going on? Heuristically, if the cost function is unregularized, then the length of the weight vector is likely to grow, all other things being equal. Over time this can lead to the weight vector being very large indeed. This can cause the weight vector to get stuck pointing in more or less the same direction, since changes due to gradient descent only make tiny changes to the direction, when the length is long. I believe this phenomenon is making it hard for our learning algorithm to properly explore the weight space, and consequently harder to find good minima of the cost function.</p>
</section>
<section id="l1-regularization" class="level3">
<h3 class="anchored" data-anchor-id="l1-regularization">L1 regularization</h3>
<p><span class="math display">\[
C = any\ loss\ function  + \frac{\lambda}{n}\sum_w |w|
\]</span></p>
<p>L1 regularization is similar to l2 just the norm formulae changes from sum of squares to absolute value.</p>
<p>Updating weight formulae while backprop <span class="math display">\[
w = w - {lr} \frac{\partial C}{\partial w} - \frac {{lr} \lambda} {n} sign(w)
\]</span></p>
<p>sign(w) is just the sign of the weight vector +1 for positive weights and -1 for negative weights</p>
<section id="comparing-l1-and-l2" class="level4">
<h4 class="anchored" data-anchor-id="comparing-l1-and-l2">Comparing L1 and L2</h4>
<p>In both expressions the effect of regularization is to shrink the weights. This accords with our intuition that both kinds of regularization penalize large weights. But the way the weights shrink is different.</p>
<p>In L1 regularization, the weights shrink by a constant amount toward 0.</p>
<p>In L2 regularization, the weights shrink by an amount which is proportional to w. And so when a particular weight has a large magnitude, |w|, L1 regularization shrinks the weight much less than L2 regularization does.</p>
<p>By contrast, when |w| is small, L1 regularization shrinks the weight much more than L2 regularization. The net result is that L1 regularization tends to concentrate the weight of the network in a relatively small number of high-importance connections, while the other weights are driven toward zero.</p>
<p>Hence L1 regularization makes the <strong><code>Network Spare</code></strong>.</p>
</section>
</section>
</section>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout">Dropout</h2>
<p>Dropout is another regularization techniques which is very simple to understand.</p>
<p><img src="images/dropout.gif" class="img-fluid"></p>
<p>So it takes a probability p and based on the value of p it randomly disables that percentage of neuron.</p>
<p>For example if the dropout value is 0.3 on a layer. It will disable 30% neuron in the layer i.e zero the value of those neuron.</p>
<p>While training with every batch a different set on neurons are disabled which is completely random.</p>
<p>So why does dropout increases the robustness of the model? Heuristically, when we dropout different sets of neurons, it’s rather like we’re training different neural networks. And so the dropout procedure is like averaging the effects of a very large number of different networks. The different networks will overfit in different ways, and so, hopefully, the net effect of dropout will be to reduce overfitting.</p>
<p>For example In cnn if the model is trained on dogs vs cats example and few particular neurons having higher weight, everytime the model witnesses the whiskers in the image it activates those neurons and we get cat. But what if those whiskers are no there then model fails significantly. so dropout forces the model to learn more attributes of the training data while training.</p>
<p>when p = 0.5</p>
<p>By repeating dropout over and over, our network will learn a set of weights and biases. Of course, those weights and biases will have been learnt under conditions in which half the hidden neurons were dropped out. When we actually run the full network that means that twice as many hidden neurons will be active. To compensate for that, we halve the weights outgoing from the hidden neurons.</p>
<p>if we Pytorch implementation of Dropout their , the outputs are scaled by a factor of <span class="math display">\[ 1/(1-p)​\]</span> during training. This means that during evaluation the module simply computes an identity function.</p>
<p>There is also <code>DropConnect</code> which is on similar lines as <code>Dropout</code></p>
<section id="dropconnect" class="level4">
<h4 class="anchored" data-anchor-id="dropconnect">DropConnect</h4>
<p><img src="images/dropconnect.png" class="img-fluid"></p>
</section>
<section id="dropout-1" class="level4">
<h4 class="anchored" data-anchor-id="dropout-1">Dropout</h4>
<p><img src="images/dropoutff.png" class="img-fluid"></p>
</section>
</section>
<section id="label-smoothing" class="level2">
<h2 class="anchored" data-anchor-id="label-smoothing">Label Smoothing</h2>
<p>When we apply the cross-entropy loss to a classification task, we’re expecting true labels to have 1, while the others 0. In other words, we have no doubts that the true labels are true, and the others are not. Is that always true? Maybe not. Many manual annotations are the results of multiple participants. They might have different criteria. They might make some mistakes. They are human, after all. As a result, the ground truth labels we have had perfect beliefs on are possible wrong.</p>
<p>The impact of this on model is First, it may result in over-fitting: if the model learns to assign full probability to the ground truth label for each training example, it is not guaranteed to generalize. Second, it encourages the differences between the largest logit and all others to become large, and this, combined with the bounded gradient reduces the ability of the model to adapt. Intuitively, this happens because the model becomes too confident about its predictions.</p>
<p>One possibile solution to this is to relax our confidence on the labels. For instance, we can slighly lower the loss target values from 1 to, say, 0.9. And naturally we increase the target value of 0 for the others slightly as such. This idea is called label smoothing.</p>
<p><a href="https://arxiv.org/pdf/1512.00567.pdf">Check the result of imagenet model after applying on imagenet</a></p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">Pytorch Supports it in Cross Entropy Loss</a></p>
</section>
</section>
<section id="data-augmentation" class="level1">
<h1>Data Augmentation</h1>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch installation</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#generic</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#torch Dependencies</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets , transforms</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset , DataLoader</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">#setting cuda for gpu in torch</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="what-is-data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="what-is-data-augmentation">what is Data Augmentation ?</h3>
<ol type="1">
<li><p>Data Augmentation is a technique to add variance in data so that the model generalizes better.</p></li>
<li><p>We Perform data augmentation more specifically image augmentation on Image data for CNNs through simple techniques, such as cropping, rotating, horizontally flip or vertically flip, swapping the channels etc.</p></li>
</ol>
<p><img src="https://cdn-images-1.medium.com/max/2600/1*bqNylp7FcqIBWg0DrcimUw.png" class="img-fluid"></p>
</section>
<section id="why-do-we-need-image-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="why-do-we-need-image-augmentation">Why do we Need Image Augmentation</h3>
<section id="suppose-you-have-trained-a-dl-model-for-cats-and-dogs-classification-and-all-the-images-are-picture-perfect-i.e-the-object-is-in-the-center-and-in-focus-and-images-are-taken-in-daylight-conditions-therefore-your-model-works-fine-." class="level5">
<h5 class="anchored" data-anchor-id="suppose-you-have-trained-a-dl-model-for-cats-and-dogs-classification-and-all-the-images-are-picture-perfect-i.e-the-object-is-in-the-center-and-in-focus-and-images-are-taken-in-daylight-conditions-therefore-your-model-works-fine-.">Suppose you have trained a DL model for Cats and Dogs Classification and all the images are picture perfect i.e the object is in the center and in focus and Images are taken in daylight conditions, therefore your model works fine .</h5>
</section>
<section id="lets-discuss-three-use-cases-in-the-context-of-the-above-problem." class="level5">
<h5 class="anchored" data-anchor-id="lets-discuss-three-use-cases-in-the-context-of-the-above-problem.">Let’s discuss three use cases in the context of the above problem.</h5>
<ol type="1">
<li>what happens when model sees a half cropped cat image or the object is in not in center and out of focus.</li>
<li>What if the model gets a low light image of dog.</li>
<li>what if your training image is size is less and it contains certain biases in the images with low variance. For example all the cats photos contains very less background i.e image is zoomed in and model gets an image of cat sitting in a park where the images contains more background.</li>
</ol>
</section>
<section id="in-all-above-cases-the-model-will-goof-up-it-will-spit-out-wrong-results." class="level5">
<h5 class="anchored" data-anchor-id="in-all-above-cases-the-model-will-goof-up-it-will-spit-out-wrong-results.">In all above cases the model will goof up, It will spit out wrong results.</h5>
</section>
</section>
<section id="what-is-the-solution-to-all-above-problems" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-solution-to-all-above-problems">What is the solution to all above problems</h3>
<section id="image-augmentation" class="level5">
<h5 class="anchored" data-anchor-id="image-augmentation">Image Augmentation</h5>
<ol type="1">
<li><p>Augmentation is also a form of adding prior knowledge to a model; e.g.&nbsp;images are rotated, which you know does not change the class label. Increasing training data (as with augmentation) decreases a model’s variance. Regularization also decreases a model’s variance. They do so in different ways, but ultimately both decrease regularization error.</p></li>
<li><p>A convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, a CNN can be invariant to translation, viewpoint, size or illumination (Or a combination of the above).</p></li>
<li><p>With Data Augmentation you make the model robust even when training set is small by giving inputs of images accounting for most different situations. ex:- Different Lighting conditions. <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSTUUnxINkVeJLQVbs8JjTlStNXmT7fW5dfQ3428UZ_yb8JouyS.png" class="img-fluid"></p></li>
</ol>
<section id="the-above-augmentation-is-sign-board-for-self-driving-cars." class="level6">
<h6 class="anchored" data-anchor-id="the-above-augmentation-is-sign-board-for-self-driving-cars.">The above Augmentation is sign board for self driving cars.</h6>
</section>
<section id="you-can-realize-the-neccesity-of-image-augmenation-from-this-image-as-the-self-driving-car-should-able-to-recognize-the-stop-sign-board-in-any-case" class="level6">
<h6 class="anchored" data-anchor-id="you-can-realize-the-neccesity-of-image-augmenation-from-this-image-as-the-self-driving-car-should-able-to-recognize-the-stop-sign-board-in-any-case">You can realize the neccesity of image Augmenation from this image as the self driving car should able to recognize the stop sign board in any case</h6>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*_mgTLhXwWGDEgz_2C7dRDg.png" class="img-fluid"></p>
</section>
<section id="what-are-the-various-augmentation-techniques-to-be-performed-on-different-kinds-of-data" class="level6">
<h6 class="anchored" data-anchor-id="what-are-the-various-augmentation-techniques-to-be-performed-on-different-kinds-of-data">what are the various augmentation techniques to be performed on different kinds of data</h6>
<p><img src="https://i.ytimg.com/vi/Kmypbz3wVko/maxresdefault.jpg" class="img-fluid"></p>
</section>
</section>
</section>
<section id="do-we-need-augmentation-if-training-data-set-is-huge" class="level3">
<h3 class="anchored" data-anchor-id="do-we-need-augmentation-if-training-data-set-is-huge">Do we need Augmentation If training data set is huge?</h3>
</section>
<section id="data-augmentation-in-pytorch-and-visualization" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation-in-pytorch-and-visualization">Data Augmentation in Pytorch and visualization</h3>
<ol type="1">
<li><p>Pytorch and Keras support a basic set of image augmentation techniques.</p></li>
<li><p>For more Advance Augmentation refer these libraries <a href="https://imgaug.readthedocs.io/en/latest/">ImgAug</a>, <a href="https://github.com/albu/albumentations">albumentation</a> and <a href="https://github.com/mdbloice/Augmentor">Augmentor</a>.</p></li>
<li><p>They support a wide range of augmentation techniques, allows to easily combine these and to execute them in random order or on multiple CPU cores, has a simple yet powerful stochastic interface and can not only augment images, but also keypoints/landmarks, bounding boxes, heatmaps and segmentation maps.</p></li>
</ol>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-02-22T08:33:03.278009Z&quot;,&quot;start_time&quot;:&quot;2019-02-22T08:33:03.261657Z&quot;}" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Transforms are common image transformations. They can be chained together using Compose.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># pytorch gives many transformation on PIL image so if you get a tensor by default first convert it to PIL image then apply transformation </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and then convert back to tensor or else it can be used directly</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.RandomRotation((<span class="dv">0</span>,<span class="dv">5</span>),resample <span class="op">=</span> PIL.Image.NEAREST), </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                                 transforms.ColorJitter(brightness<span class="op">=</span><span class="fl">0.5</span>, contrast<span class="op">=</span><span class="dv">0</span>, saturation<span class="op">=</span><span class="dv">0</span>, hue<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                                 transforms.RandomHorizontalFlip(p<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                                 transforms.CenterCrop(size<span class="op">=</span><span class="dv">26</span>),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                                transforms.ToTensor()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-02-22T08:33:25.769317Z&quot;,&quot;start_time&quot;:&quot;2019-02-22T08:33:22.935985Z&quot;}" data-outputid="f83f9df5-f55a-447d-8159-d798d9ce9b99" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>trainSet <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">"./data/pytorch"</span> , train<span class="op">=</span><span class="va">True</span>,download<span class="op">=</span><span class="va">True</span> , transform <span class="op">=</span>transforms.ToTensor() ) <span class="co">#This returns the dataset </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>trainLoader <span class="op">=</span> DataLoader(trainSet , batch_size<span class="op">=</span><span class="dv">8</span>) <span class="co"># Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>trainSetAug <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">"./data/pytorch"</span> , train<span class="op">=</span><span class="va">True</span>,download<span class="op">=</span><span class="va">True</span>,transform<span class="op">=</span>transform) <span class="co">#This returns the dataset </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>trainLoaderAug <span class="op">=</span> DataLoader(trainSetAug , batch_size<span class="op">=</span><span class="dv">8</span>) <span class="co"># Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> (<span class="st">'plane'</span>, <span class="st">'car'</span>, <span class="st">'bird'</span>, <span class="st">'cat'</span> , <span class="st">'deer'</span>, <span class="st">'dog'</span>, <span class="st">'frog'</span>, <span class="st">'horse'</span>, <span class="st">'ship'</span>, <span class="st">'truck'</span>)<span class="co"># cifar 10 classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified</code></pre>
</div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-02-22T08:32:15.733645Z&quot;,&quot;start_time&quot;:&quot;2019-02-22T08:32:15.723445Z&quot;}" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denormalize(image):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#because pytorch takes data in C * H * W  order we need to convert to H * W* C for visualizing in pytorch</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  image <span class="op">=</span> image.permute(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>) <span class="co"># it transposes the dimensions</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> image</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-02-22T08:35:40.500354Z&quot;,&quot;start_time&quot;:&quot;2019-02-22T08:35:39.586402Z&quot;}" data-outputid="67788ae9-dd24-4eee-dd4b-d1f4484a4788" data-execution_count="36">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#As we can see we have given batch size of 8 so</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># visualizing the image</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>images , labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(trainLoader))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>nrows<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="bu">len</span>(images)<span class="op">//</span>nrows </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">7</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images)):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  plt.subplot(nrows,ncols,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  plt.grid(<span class="va">False</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  plt.imshow(denormalize(images[i]))</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  plt.title(classes[labels[i]])</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regularization_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-02-22T08:35:51.532311Z&quot;,&quot;start_time&quot;:&quot;2019-02-22T08:35:50.731125Z&quot;}" data-execution_count="38">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>images , labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(trainLoaderAug))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>nrows<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="bu">len</span>(images)<span class="op">//</span>nrows </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>,<span class="dv">7</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images)):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  plt.subplot(nrows,ncols,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  plt.grid(<span class="va">False</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  plt.imshow(denormalize(images[i]))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  plt.title(classes[labels[i]])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regularization_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="lets-see-something-different" class="level3">
<h3 class="anchored" data-anchor-id="lets-see-something-different">Let’s see something different</h3>
<div class="cell" data-outputid="e88a78a2-c79f-440c-8782-3a900fc6cd81" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make your data </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> download_images(root_dir , list_of_images):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> index , image_url <span class="kw">in</span> <span class="bu">enumerate</span>(list_of_images):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.get(image_url , stream<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(root_dir<span class="op">/</span><span class="st">"</span><span class="sc">{}</span><span class="st">.jpg"</span>.<span class="bu">format</span>(index) , <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> chunks <span class="kw">in</span> r.iter_content(chunk_size<span class="op">=</span><span class="dv">1024</span>):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> chunks:</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>          f.write(chunks)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>list_of_images <span class="op">=</span> [</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRTEJpqf8laCz0tzwRVdQA-kVMkUorZqVtc9CvYsHvtHSjqb2v6"</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://www.gettyimages.in/gi-resources/images/Embed/new/embed2.jpg"</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"http://www.personal.ceu.hu/students/17/Marina_Tomovic/Images/955d4284905d149ea4967ff586e89b41.jpg"</span>,</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://d12m9erqbesehq.cloudfront.net/wp-content/uploads/sites/5150/2016/04/13100027/images-4.jpg"</span>,</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>root_dir <span class="op">=</span> Path(<span class="st">"my_data/train"</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> root_dir.exists():</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  root_dir.mkdir(parents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>download_images(root_dir , list_of_images)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>index<span class="op">=</span><span class="dv">0</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>))</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> datasets.ImageFolder(<span class="bu">str</span>(root_dir<span class="op">/</span><span class="st">".."</span>)):</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  index<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">4</span>,<span class="dv">1</span> ,index)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  plt.imshow(i[<span class="dv">0</span>])      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regularization_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="normalization" class="level4">
<h4 class="anchored" data-anchor-id="normalization">Normalization</h4>
<div class="cell" data-outputid="0310d27e-c079-444d-c813-79f702a2015f" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Other important technique is normalization of image we do a channel wise normalization by subtracting the channel wise mean by standard deviation </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># we perform this to keep all the input images in similar range and thus getting a stable gradient</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> datasets.CIFAR10(<span class="st">'./data/pytorch'</span>, train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># use np.concatenate to stick all the images together to form a 1600000 X 32 X 3 array</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.concatenate([np.asarray(train_data[i][<span class="dv">0</span>]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(train_data))], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(x)</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the mean and std along the (0, 1) axe</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.mean(x,axis<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>std<span class="op">=</span>np.std(x,axis<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean , std)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>mean , std <span class="op">=</span> torch.tensor([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]),torch.tensor([<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(1600000, 32, 3)
[125.30691805 122.95039414 113.86538318] [62.99321928 62.08870764 66.70489964]</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The Updated transforms with normalization </span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.RandomAffine((<span class="dv">5</span>,<span class="dv">10</span>), scale<span class="op">=</span>(<span class="dv">1</span>,<span class="fl">1.5</span>) ,resample<span class="op">=</span>PIL.Image.NEAREST),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                                transforms.RandomHorizontalFlip(p<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                                transforms.Resize((<span class="dv">224</span>,<span class="dv">224</span>)),</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>                                transforms.ToTensor(),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                                transforms.Normalize(mean ,std)]) <span class="co">## normalize</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> datasets.ImageFolder(<span class="bu">str</span>(root_dir<span class="op">/</span><span class="st">".."</span>) , transform)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>trainLoader <span class="op">=</span> DataLoader(trainset , batch_size<span class="op">=</span><span class="dv">4</span>,shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-outputid="ffa9f91c-b208-46ad-903c-90ba01de51ea" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denormalize(image):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  image <span class="op">=</span> transforms.Normalize(<span class="op">-</span>mean<span class="op">/</span>std,<span class="dv">1</span><span class="op">/</span>std)(image) <span class="co">#denormalize</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  image <span class="op">=</span> image.permute(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>) </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  image <span class="op">=</span> torch.clamp(image,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> image</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(trainLoader))</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>images , labels <span class="op">=</span> data</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>nrows<span class="op">=</span><span class="dv">2</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>ncols <span class="op">=</span> <span class="bu">len</span>(data[<span class="dv">0</span>])<span class="op">//</span>nrows </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>,<span class="dv">7</span>))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images)):</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  plt.subplot(nrows,ncols,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  plt.grid(<span class="va">False</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  plt.imshow(denormalize(images[i]))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  plt.title(classes[labels[i]])</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regularization_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="so-now-that-you-have-learnt-data-augmentation-techniques.-the-problem-statement-should-be-scrtunized-well-before-applying-any-augmentation-to-the-dataset.-dont-increase-irrelevant-data." class="level5">
<h5 class="anchored" data-anchor-id="so-now-that-you-have-learnt-data-augmentation-techniques.-the-problem-statement-should-be-scrtunized-well-before-applying-any-augmentation-to-the-dataset.-dont-increase-irrelevant-data.">So now that you have learnt Data Augmentation techniques. The problem statement should be scrtunized well before applying any augmentation to the dataset. Don’t increase irrelevant data.</h5>
</section>
</section>
</section>
<section id="early-stopping" class="level2">
<h2 class="anchored" data-anchor-id="early-stopping">Early Stopping</h2>
<p>Monitor the model’s performance on a validation set during training and stop when the performance starts degrading. This prevents the model from overfitting the training data.</p>
<p>Here you can look at the code to implement the same <a href="https://pytorch.org/ignite/_modules/ignite/handlers/early_stopping.html#EarlyStopping">link</a></p>
</section>
<section id="weight-clipping-and-gradient-clipping" class="level2">
<h2 class="anchored" data-anchor-id="weight-clipping-and-gradient-clipping">Weight Clipping and Gradient Clipping</h2>
<ol type="1">
<li>Limit the magnitude of weights in the network to prevent them from becoming too large. This can be achieved using techniques like weight clipping.</li>
<li>Limit the gradients during training to prevent exploding gradients. This is especially useful in recurrent neural networks (RNNs).</li>
</ol>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> model(inputs)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(out, labels)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(i, loss.item())</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    opt.zero_grad()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># standard way of clipping the gradient</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># another way of doing it</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html#clip_grad_value_</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        param.grad.clamp_(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># weight clipping in range of -1 to 1</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    opt.step()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>            param.clamp_(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># weight clipping in range of -1 to 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="pruning" class="level2">
<h2 class="anchored" data-anchor-id="pruning">Pruning</h2>
<p><img src="images/pruning.png" class="img-fluid"> Pruning is a technique that removes weights or biases (parameters) from a neural network model. Now there are many ways of doing it based on different criteria and what the need is overall if done properly , makes the model training/inference fast, better generalization, resource friendly.</p>
<p>Follow few tutorials</p>
<p><a href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#global-pruning">Tutorial</a></p>
<p><a href="https://pytorch.org/docs/stable/nn.html#module-torch.nn.utils">Doc</a></p>
</section>
</section>
<section id="normalization-and-standardization" class="level1">
<h1>Normalization and Standardization</h1>
<p>Normalization is also a regularization technique where we equalize all the attributes of a model and bring them down to normal standard. So what actually is normal standard, let’s see with a example. Suppose in the cnn model if some neuron is very active by having a high weight then all other neurons with small weight won’t be able to contribute to model more so with normalization we bring down all the neurons to small scale.</p>
<section id="look-at-this-image-below" class="level4">
<h4 class="anchored" data-anchor-id="look-at-this-image-below">Look at this image below:</h4>
<p><img src="images/cnnfilter.jpg" class="img-fluid"> ### There is something wrong with this image.</p>
</section>
<section id="lets-look-at-the-greyscale-version-of-this-image-to-learn-more." class="level4">
<h4 class="anchored" data-anchor-id="lets-look-at-the-greyscale-version-of-this-image-to-learn-more.">Let’s look at the greyscale version of this image to learn more.</h4>
<p><img src="images/cnnfilter_bnw.png" class="img-fluid"> What is wrong here is, that the amplitudes of these kernels are not “similar”, which means even though they have learnt what do do, their contribution would not be carried forward a lot. We need to normalize them.</p>
</section>
<section id="this-is-the-effect-of-normalization-on-these-kernels" class="level4">
<h4 class="anchored" data-anchor-id="this-is-the-effect-of-normalization-on-these-kernels">This is the effect of normalization on these kernels:</h4>
<p><img src="images/cnnfilter_bnw_eql.png" class="img-fluid"></p>
</section>
<section id="normalization-has-now-tried-to-equalize-the-kernels-i.e.-pulled-up-the-values." class="level4">
<h4 class="anchored" data-anchor-id="normalization-has-now-tried-to-equalize-the-kernels-i.e.-pulled-up-the-values.">Normalization has now tried to equalize the kernels, i.e.&nbsp;pulled up the values.</h4>
</section>
<section id="lets-look-at-these-in-3d.-remember-the-3d-component-here-is-just-for-reference-and-represent-the-amplitudes." class="level4">
<h4 class="anchored" data-anchor-id="lets-look-at-these-in-3d.-remember-the-3d-component-here-is-just-for-reference-and-represent-the-amplitudes.">Let’s look at these in 3d. Remember the 3D component here is just for reference, and represent the amplitudes.</h4>
<p>These are normal kernels: <img src="images/ezgif-4-024a490477.gif" class="img-fluid"></p>
</section>
<section id="these-kernels-are-now-normalized" class="level4">
<h4 class="anchored" data-anchor-id="these-kernels-are-now-normalized">These kernels are now “normalized”:</h4>
<p><img src="images/ezgif-4-6ba4093f05.gif" class="img-fluid"></p>
<p>In statistics we perform standardization by calculting z-score <span class="math display">\[
z = \frac{x-\mu}{\sigma}
\]</span></p>
<p>In statistics we perform Normalization by various I am showing min max scaler ways <span class="math display">\[
z = \frac{x-x_{min}}{x_{max}-x_{min}}
\]</span></p>
<p><img src="images/bellcurve.jpg" class="img-fluid"></p>
<p>The special property of this new standarized data is <strong>it has zero mean and one standard deviation</strong></p>
<p><code>Note</code>:- Standardization and Normalization doesn’t make a distribution a standard normal because there are just linear transformation.</p>
<p>There are many normalization techniques but specially in CNNs we primarly use Batch norm which is based on the above described math.</p>
</section>
<section id="batch-normalization" class="level3">
<h3 class="anchored" data-anchor-id="batch-normalization">Batch Normalization</h3>
<p>Batch normalization reduces the amount by what the hidden unit values shift around (covariance shift). To explain covariance shift, let’s have a deep network on cat detection. We train our data on only black cats’ images. So, if we now try to apply this network to data with colored cats, it is obvious; we’re not going to do well. The training set and the prediction set are both cats’ images but they differ a little bit. In other words, if an algorithm learned some X to Y mapping, and if the distribution of X changes, then we might need to retrain the learning algorithm by trying to align the distribution of X with the distribution of Y. ( Deeplearning.ai: Why Does Batch Norm Work? (C2W3L06))</p>
<p>Also, Covariance shift, in the context of batch normalization (BatchNorm), is phenomenon where the statistical properties of the input to a neural network’s layer change as the network trains. Specifically, it refers to changes in the mean and variance of the input data distribution at different layers of a deep neural network during the training process.</p>
<p>Also, batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers.</p>
<p>We can use higher learning rates because batch normalization makes sure that there’s no activation that’s gone really high or really low. And by that, things that previously couldn’t get to train, it will start to train.</p>
<p>It reduces overfitting because it has a slight regularization effects. Similar to dropout, it adds some noise to each hidden layer’s activations. Therefore, if we use batch normalization, we will use less dropout, which is a good thing because we are not going to lose a lot of information. However, we should not depend only on batch normalization for regularization; we should better use it together with dropout.</p>
<section id="how-it-works" class="level4">
<h4 class="anchored" data-anchor-id="how-it-works">How it works?</h4>
<p>So we use batch norm as layer before the activation layer which normalizies the data by subtracting the batch data with batch mean and then dividing by batch standard deviation.</p>
<p>After normalizing the layer the weights are shifted/scaled by some value for the next layer now what if the model wants to undo the normalization operation to decrease the loss, model should have some control of that, therefore we introduce two more learnable parameters gamma and beta.</p>
<p>Where gamma can be the standard deviation and beta the mean value to perform the denormalization operation</p>
<p><img src="images/batch_norm.png" width="50%" height="200"></p>
</section>
</section>
<section id="weight-norm" class="level3">
<h3 class="anchored" data-anchor-id="weight-norm"><a href="https://arxiv.org/pdf/1602.07868.pdf">Weight Norm</a></h3>
<p>BatchNorm: BatchNorm normalizes the activations of a layer by computing the mean and variance statistics within each mini-batch during training. It normalizes the activations of a layer based on the statistics of the current mini-batch.</p>
<p>WeightNorm: WeightNorm, on the other hand, normalizes the weights (parameters) of a neural network layer. It scales and normalizes the weights themselves, not the activations.</p>
</section>
<section id="layer-norm" class="level3">
<h3 class="anchored" data-anchor-id="layer-norm">Layer Norm</h3>
<p>This is also a normalizing technique similar batch norm but it performs its operation on layers of the batch and used in RNNs.</p>
<p><img src="images/weight_layer_norm.webp" class="img-fluid"></p>
<p><img src="images/batch_layer.jpg" class="img-fluid"></p>
<p>Let’s take an example of input size <code>(32,100,64,64)</code> where <code>32</code> is batch size <code>100</code> channel or feature and <code>64</code>, <code>64</code> is Height and width</p>
<p>Batch Norm happens across batch in dimension -&gt; <code>0,2,3</code> we calculate mean, hence for <code>100</code> features we are left with <code>100</code> values we calculate mean across batches and features, i.e pick a channel for all <code>32</code> batches each of size <code>64</code>,<code>64</code> take the mean.</p>
<p>Layer Norm -&gt; removes the dependecy on batch we take mean across dimension -&gt; <code>1,2,3</code> hence for each image which has got <code>100</code> channels calculate a single value and finally we will left with <code>32</code> values, treat example independently.</p>
<p>Instance Norm -&gt; takes the idea of layer norm and pushes it too much we take mean across-&gt; <code>0,1</code>, calculate mean per image per channel</p>
<section id="batch-norm-for-cnn-layer-norm-for-rnn-and-transformer-models." class="level4">
<h4 class="anchored" data-anchor-id="batch-norm-for-cnn-layer-norm-for-rnn-and-transformer-models.">Batch Norm for CNN, Layer Norm for RNN and Transformer Models.</h4>
</section>
</section>
<section id="thank-you." class="level2">
<h2 class="anchored" data-anchor-id="thank-you.">Thank you.</h2>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/aman5319\.github\.io\/portfolio\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aman5319/portfolio" data-repo-id="R_kgDOJ44pkw" data-category="Q&amp;A" data-category-id="DIC_kwDOJ44pk84CXwVt" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../posts/Machine Learning/metrics.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Metrics for Machine Learning</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../posts/Machine Learning/Weight_Initializer.html" class="pagination-link">
        <span class="nav-page-text">Weight Intialization</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Blog made with 💜 and <a href="https://quarto.org/">Quarto</a>, by Aman Pandey. License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:amanpandey@mailfence.com">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>