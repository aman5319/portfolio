<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aman Pandey">
<meta name="dcterms.date" content="2019-10-15">
<meta name="description" content="We go through RNN, LSTM, GRU building intution and coding from scratch to understand forward and backward pass.">

<title>Aman’s Blog - RNN Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../posts/Optimization/optimisers_in_dl.html" rel="next">
<link href="../../posts/NLP/nlp_overview.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Aman’s Blog - RNN Models">
<meta property="og:description" content="We go through RNN, LSTM, GRU building intution and coding from scratch to understand forward and backward pass.">
<meta property="og:image" content="https://aman5319.github.io/portfolio/posts/NLP/images/rnn_arch.png">
<meta property="og:site-name" content="Aman's Blog">
<meta property="og:image:height" content="478">
<meta property="og:image:width" content="1026">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Aman’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target=""><i class="bi bi-file-person" role="img">
</i> 
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://drive.google.com/drive/folders/1pTPR0vPX1UoQYfyvQLu8Pn-Wc6hqrjGf?usp=sharing" rel="" target="_blank"><i class="bi bi-file-pdf" role="img">
</i> 
 <span class="menu-text">Resume</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/aman5319" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/aman5319/" rel="" target="_blank"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Posts</li><li class="breadcrumb-item"><a href="../../posts/NLP/embeddings.html">NLP</a></li><li class="breadcrumb-item"><a href="../../posts/NLP/rnn_lstm_gru.html">RNN Models</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">RNN Models</h1>
                  <div>
        <div class="description">
          We go through RNN, LSTM, GRU building intution and coding from scratch to understand forward and backward pass.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep-learning</div>
                <div class="quarto-category">nlp</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Aman Pandey </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 15, 2019</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Computer Vision</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Computer Vision/convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolution and Common architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Computer Vision/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Different types of Attentions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics for Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Improve Model’s Prediction power using Regularization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Machine Learning/Weight_Initializer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Weight Intialization</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">NLP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/linguistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linguistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/nlp_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NLP Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/NLP/rnn_lstm_gru.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">RNN Models</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Optimization/optimisers_in_dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Optimizers in - Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/big_data_processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Big Data Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/functional_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Functional Programming capabilites of python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/parallel_processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallelism and Concurrency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Python/profiling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Memory and Time Profiling</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#models" id="toc-models" class="nav-link active" data-scroll-target="#models">Models</a></li>
  <li><a href="#different-rnn-architectures" id="toc-different-rnn-architectures" class="nav-link" data-scroll-target="#different-rnn-architectures">Different RNN Architectures</a></li>
  <li><a href="#recurrent-neural-network" id="toc-recurrent-neural-network" class="nav-link" data-scroll-target="#recurrent-neural-network">Recurrent Neural Network</a></li>
  <li><a href="#time-to-code..--rnn-cell" id="toc-time-to-code..--rnn-cell" class="nav-link" data-scroll-target="#time-to-code..--rnn-cell">Time to Code.. -RNN Cell</a></li>
  <li><a href="#rnn-forward-pass" id="toc-rnn-forward-pass" class="nav-link" data-scroll-target="#rnn-forward-pass">RNN Forward Pass</a></li>
  <li><a href="#time-to-code-rnn-forward-pass" id="toc-time-to-code-rnn-forward-pass" class="nav-link" data-scroll-target="#time-to-code-rnn-forward-pass">Time to Code… RNN Forward Pass</a></li>
  <li><a href="#backpropagation-through-time-bptt" id="toc-backpropagation-through-time-bptt" class="nav-link" data-scroll-target="#backpropagation-through-time-bptt">Backpropagation through time (BPTT)</a>
  <ul class="collapse">
  <li><a href="#backprop-for-w_y" id="toc-backprop-for-w_y" class="nav-link" data-scroll-target="#backprop-for-w_y">BackProp For <span class="math inline">\(W_y\)</span></a></li>
  <li><a href="#backprop-for-w_s" id="toc-backprop-for-w_s" class="nav-link" data-scroll-target="#backprop-for-w_s">Backprop for <span class="math inline">\(W_s\)</span></a></li>
  <li><a href="#backprop-for-w_x" id="toc-backprop-for-w_x" class="nav-link" data-scroll-target="#backprop-for-w_x">Backprop for <span class="math inline">\(W_x\)</span></a></li>
  </ul></li>
  <li><a href="#vanishing-gradient" id="toc-vanishing-gradient" class="nav-link" data-scroll-target="#vanishing-gradient">Vanishing Gradient</a></li>
  <li><a href="#long-short-term-memory-lstm-network---generalized-version-of-gru" id="toc-long-short-term-memory-lstm-network---generalized-version-of-gru" class="nav-link" data-scroll-target="#long-short-term-memory-lstm-network---generalized-version-of-gru">Long Short-Term Memory (LSTM) network - Generalized version of GRU</a>
  <ul class="collapse">
  <li><a href="#forget-gate" id="toc-forget-gate" class="nav-link" data-scroll-target="#forget-gate">- Forget gate</a></li>
  <li><a href="#update-gate" id="toc-update-gate" class="nav-link" data-scroll-target="#update-gate">- Update gate</a></li>
  <li><a href="#updating-the-cell" id="toc-updating-the-cell" class="nav-link" data-scroll-target="#updating-the-cell">- Updating the cell</a></li>
  <li><a href="#output-gate" id="toc-output-gate" class="nav-link" data-scroll-target="#output-gate">- Output gate</a></li>
  </ul></li>
  <li><a href="#time-to-code--lstm-cell" id="toc-time-to-code--lstm-cell" class="nav-link" data-scroll-target="#time-to-code--lstm-cell">Time to Code -LSTM Cell</a></li>
  <li><a href="#lstm-forward-pass" id="toc-lstm-forward-pass" class="nav-link" data-scroll-target="#lstm-forward-pass">LSTM Forward Pass</a></li>
  <li><a href="#gru-simplified" id="toc-gru-simplified" class="nav-link" data-scroll-target="#gru-simplified">GRU Simplified</a></li>
  <li><a href="#gru-full" id="toc-gru-full" class="nav-link" data-scroll-target="#gru-full">GRU Full</a>
  <ul class="collapse">
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">Thank you</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.dev/aman5319/portfolio/blob/main/posts/NLP/rnn_lstm_gru.ipynb" class="toc-action">Edit this page</a></p><p><a href="https://github.com/aman5319/portfolio/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T14:14:11.642806Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T14:14:11.637819Z&quot;}" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(x):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    e_x <span class="op">=</span> np.exp(x <span class="op">-</span> np.<span class="bu">max</span>(x))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> e_x <span class="op">/</span> e_x.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We don’t use Normal MLP to handle textual data because they</p>
<ol type="1">
<li>Inputs, outputs can be of different lengths in different examples</li>
<li>Maintain information about the order of text</li>
<li>Share parameters across the sequence : Doesnot share features learned across different positions of text.</li>
<li>Number of training parameters should be less.</li>
</ol>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">Models</h3>
<ol type="1">
<li>RNN</li>
<li>LSTM</li>
<li>BI-LSTM</li>
<li>GRU</li>
<li>CNNs</li>
</ol>
</section>
<section id="different-rnn-architectures" class="level3">
<h3 class="anchored" data-anchor-id="different-rnn-architectures">Different RNN Architectures</h3>
<ol type="1">
<li>One to One</li>
<li>One to Many</li>
<li>Many to One</li>
<li>Many to Many</li>
<li>Many to Many ( of different length)</li>
</ol>
<p><img src="images/rnn_arch.png" class="img-fluid"></p>
</section>
<section id="recurrent-neural-network" class="level1">
<h1>Recurrent Neural Network</h1>
<p>Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have “memory”. They can read inputs <span class="math inline">\(x^{\langle t \rangle}\)</span> (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a uni-directional RNN to take information from the past to process later inputs.</p>
<ol type="1">
<li>Recurrent Neural Network scans through the data from left to right.</li>
<li>Weight Parameters (Wax) between input and hidden layer is shared at every time step.</li>
<li>Weight parameters (Waa) of hidden layers is shared at every time step.</li>
<li>Weight parameters (Wya) of the output prediction is shared at every time step.</li>
</ol>
<p><img src="images/rnn.png" class="img-fluid"></p>
<p><img src="images/rnn_computation_graph.PNG" class="img-fluid"></p>
</section>
<section id="time-to-code..--rnn-cell" class="level1">
<h1>Time to Code.. -RNN Cell</h1>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T14:14:03.868595Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T14:14:00.956156Z&quot;}" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: rnn_cell_forward</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rnn_cell_forward(xt, a_prev, parameters):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Implements a single forward step of the RNN-cell as described in Figure (2)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">    xt -- your input data at timestep "t", numpy array of shape (n_x, m).</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">    a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m)</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">    parameters -- python dictionary containing:</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">                        ba --  Bias, numpy array of shape (n_a, 1)</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">    a_next -- next hidden state, of shape (n_a, m)</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">    yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m)</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">    cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve parameters from "parameters"</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    Wax <span class="op">=</span> parameters[<span class="st">"Wax"</span>]</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    Waa <span class="op">=</span> parameters[<span class="st">"Waa"</span>]</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    Wya <span class="op">=</span> parameters[<span class="st">"Wya"</span>]</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    ba <span class="op">=</span> parameters[<span class="st">"ba"</span>]</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    by <span class="op">=</span> parameters[<span class="st">"by"</span>]</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE </span><span class="al">###</span><span class="co"> (≈2 lines)</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute next activation state using the formula given above</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    a_next <span class="op">=</span> np.tanh(np.dot(Wax,xt)<span class="op">+</span>np.dot(Waa,a_prev)<span class="op">+</span>ba)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute output of the current cell using the formula given above</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    yt_pred <span class="op">=</span> softmax(np.dot(Wya,a_prev)<span class="op">+</span>by)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values you need for backward propagation in cache</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    cache <span class="op">=</span> (a_next, a_prev, xt, parameters)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a_next, yt_pred, cache</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img src="images/rnn_2.PNG" class="img-fluid"></p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T14:18:20.668158Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T14:18:20.656191Z&quot;}" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">3</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Input at time step t [Vocab size[Input Vector Size] = </span><span class="sc">{}</span><span class="st">, Number of examples = </span><span class="sc">{}</span><span class="st">]"</span>.<span class="bu">format</span>(xt.shape[<span class="dv">0</span>],xt.shape[<span class="dv">1</span>]))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>a_prev <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">3</span>)  <span class="co">#[Hidden State neurons , No of Examples]</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>Waa <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">5</span>)  <span class="co">#[Previous ,Current]</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>Wax <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">10</span>)  <span class="co">#[Number of Hidden Layers,Inputer Vector Size]</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>Wya <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">5</span>)  <span class="co">#[No of outputs , Hidden State]</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>ba <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)   <span class="co">#[Number of Hidden Layers]</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>by <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">1</span>)   <span class="co">#[Number of output neurons]</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {<span class="st">"Waa"</span>: Waa, <span class="st">"Wax"</span>: Wax, <span class="st">"Wya"</span>: Wya, <span class="st">"ba"</span>: ba, <span class="st">"by"</span>: by}</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>a_next, yt_pred, cache <span class="op">=</span> rnn_cell_forward(xt, a_prev, parameters)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a_next[4] = "</span>, a_next[<span class="dv">4</span>])</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a_next.shape = "</span>, a_next.shape)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"yt_pred[1] ="</span>, yt_pred[:,<span class="dv">1</span>])</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"yt_pred[2] ="</span>, yt_pred[:,<span class="dv">2</span>])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sum over prediction for yt_pred[1]"</span>,<span class="bu">sum</span>(yt_pred[:,<span class="dv">1</span>]))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"yt_pred.shape = "</span>, yt_pred.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Input at time step t [Vocab size[Input Vector Size] = 10, Number of examples = 3]
a_next[4] =  [-0.58139971 -0.99999116  0.99815099]
a_next.shape =  (5, 3)
yt_pred[1] = [1.09976966e-03 9.30899441e-02 6.35819631e-02 2.57749868e-02
 4.43886409e-02 1.80070037e-02 2.86166616e-01 5.57862094e-03
 4.62031135e-01 2.81319496e-04]
yt_pred[2] = [0.0416935  0.32602933 0.00274785 0.00857954 0.07144196 0.02316702
 0.05565261 0.05245049 0.41108951 0.00714818]
Sum over prediction for yt_pred[1] 0.9999999999999999
yt_pred.shape =  (10, 3)</code></pre>
</div>
</div>
</section>
<section id="rnn-forward-pass" class="level1">
<h1>RNN Forward Pass</h1>
<p>You can see an RNN as the repetition of the cell you’ve just built. If your input sequence of data is carried over 10 time steps, then you will copy the RNN cell 10 times. Each cell takes as input the hidden state from the previous cell (<span class="math inline">\(a^{\langle t-1 \rangle}\)</span>) and the current time-step’s input data (<span class="math inline">\(x^{\langle t \rangle}\)</span>). It outputs a hidden state (<span class="math inline">\(a^{\langle t \rangle}\)</span>) and a prediction (<span class="math inline">\(y^{\langle t \rangle}\)</span>) for this time-step.</p>
<p><img src="images/rnn_forward.png" class="img-fluid"></p>
</section>
<section id="time-to-code-rnn-forward-pass" class="level1">
<h1>Time to Code… RNN Forward Pass</h1>
<p><img src="images/rnn_fp.PNG" class="img-fluid"></p>
<p><strong>What we will try to do:</strong> 1. Create a vector of zeros (<span class="math inline">\(a\)</span>) that will store all the hidden states computed by the RNN. 2. Initialize the “next” hidden state as <span class="math inline">\(a_0\)</span> (initial hidden state). 3. Start looping over each time step, your incremental index is <span class="math inline">\(t\)</span> : - Update the “next” hidden state and the cache by running <code>rnn_cell_forward</code> - Store the “next” hidden state in <span class="math inline">\(a\)</span> (<span class="math inline">\(t^{th}\)</span> position) - Store the prediction in y - Add the cache to the list of caches 4. Return <span class="math inline">\(a\)</span>, <span class="math inline">\(y\)</span> and caches</p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:20.266731Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:20.234314Z&quot;}" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rnn_forward(x, a0, parameters):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Implement the forward propagation of the recurrent neural network described in Figure (3).</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    x -- Input data for every time-step, of shape (n_x, m, T_x).</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    a0 -- Initial hidden state, of shape (n_a, m)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">    parameters -- python dictionary containing:</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">                        ba --  Bias numpy array of shape (n_a, 1)</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">    y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">    caches -- tuple of values needed for the backward pass, contains (list of caches, x)</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize "caches" which will contain the list of all caches</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    caches <span class="op">=</span> []</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve dimensions from shapes of x and parameters["Wya"]</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    n_x, m, T_x <span class="op">=</span> x.shape</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    n_y, n_a <span class="op">=</span> parameters[<span class="st">"Wya"</span>].shape</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE </span><span class="al">###</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initialize "a" and "y" with zeros (≈2 lines)</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_a,m,T_x))</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_y,m,T_x))</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a_next (≈1 line)</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    a_next <span class="op">=</span> a0</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over all time-steps</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T_x):</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update next hidden state, compute the prediction, get the cache (≈1 line)</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        a_next, yt_pred, cache <span class="op">=</span> rnn_cell_forward(x[:,:,t],a_next,parameters)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the value of the new "next" hidden state in a (≈1 line)</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        a[:,:,t] <span class="op">=</span> a_next</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the value of the prediction in y (≈1 line)</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        y_pred[:,:,t] <span class="op">=</span> yt_pred</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append "cache" to "caches" (≈1 line)</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        caches.append(cache)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values needed for backward propagation in cache</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    caches <span class="op">=</span> (caches, x)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a, y_pred, caches</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:21.015947Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:20.995645Z&quot;}" data-execution_count="25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>a0 <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">3</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>Waa <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">5</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>Wax <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">10</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>Wya <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>ba <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>by <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">1</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {<span class="st">"Waa"</span>: Waa, <span class="st">"Wax"</span>: Wax, <span class="st">"Wya"</span>: Wya, <span class="st">"ba"</span>: ba, <span class="st">"by"</span>: by}</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>a, y_pred, caches <span class="op">=</span> rnn_forward(x, a0, parameters)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a[4][1] = "</span>, a[<span class="dv">4</span>][<span class="dv">1</span>])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a.shape = "</span>, a.shape)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_pred[1] ="</span>, y_pred[<span class="dv">1</span>])</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_pred.shape = "</span>, y_pred.shape)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"caches[1][1] ="</span>, caches[<span class="dv">1</span>][<span class="dv">1</span>])</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"len(caches) = "</span>, <span class="bu">len</span>(caches))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a[4][1] =  [ 0.98028748 -0.99999906 -0.9988861  -0.97705431]
a.shape =  (5, 3, 4)
y_pred[1] = [[0.01239777 0.05413115 0.00182671 0.00035798]
 [0.0010342  0.00521164 0.03933742 0.00097552]
 [0.13199273 0.00056664 0.00615254 0.02599894]]
y_pred.shape =  (10, 3, 4)
caches[1][1] = [[-0.3224172  -0.38405435  1.13376944 -1.09989127]
 [-0.17242821 -0.87785842  0.04221375  0.58281521]
 [-1.10061918  1.14472371  0.90159072  0.50249434]]
len(caches) =  2</code></pre>
</div>
</div>
</section>
<section id="backpropagation-through-time-bptt" class="level1">
<h1>Backpropagation through time (BPTT)</h1>
<p><img src="images/screen-shot-2017-11-27-at-1.58.01-pm.png" class="img-fluid"></p>
<section id="backprop-for-w_y" class="level2">
<h2 class="anchored" data-anchor-id="backprop-for-w_y">BackProp For <span class="math inline">\(W_y\)</span></h2>
<p><span class="math display">\[
\frac{\partial E_3}{\partial W_y} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial W_y} \\\frac{\partial E_2}{\partial W_y} = \frac{\partial E_2}{\partial \bar y_2}. \frac{\partial \bar y_2}{\partial W_y} \\\frac{\partial E_1}{\partial W_y} = \frac{\partial E_1}{\partial \bar y_1}. \frac{\partial \bar y_1}{\partial W_y}\\
\]</span></p>
<p>General Equation <span class="math display">\[
\frac{\partial E_N}{\partial W_y} = \frac{\partial E_N}{\partial \bar y_N}. \frac{\partial \bar y_N}{\partial W_y}
\]</span></p>
</section>
<section id="backprop-for-w_s" class="level2">
<h2 class="anchored" data-anchor-id="backprop-for-w_s">Backprop for <span class="math inline">\(W_s\)</span></h2>
<p>At time step t=3 the gradient contribution for <span class="math display">\[ {\bar s_3}\]</span> is</p>
<p><span class="math display">\[
\frac{\partial E_3}{\partial W_x} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar W_s}
\]</span> At time step t=2 the gradient contribution for <span class="math display">\[ \bar s_2 \]</span> is <span class="math display">\[
\frac{\partial E_3}{\partial W_s} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} .\frac{\partial \bar s_2}{\partial \bar W_s}
\]</span> At time step t=1 the gradient contribution for <span class="math display">\[ \bar s_1\]</span> is <span class="math display">\[
\frac{\partial E_3}{\partial W_s} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} . \frac{\partial \bar s_2}{\partial \bar s_1} . \frac{\partial \bar s_1}{\partial \bar W_s}
\]</span> After considering the contributions from all three states: <span class="math display">\[\bar{s_3}\]</span> ,<span class="math display">\[\bar{s_2}\]</span> and <span class="math display">\[\bar{s_1}\]</span>, we will <strong>accumulate</strong> them to find the final gradient calculation.</p>
<p>The following equation is the gradient contributing to the adjustment of <span class="math display">\[W_s\]</span> using <strong>Backpropagation Through Time</strong>: <span class="math display">\[
\frac{\partial E_3}{\partial W_s} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar W_s} +
\\
\frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} .\frac{\partial \bar s_2}{\partial \bar W_s}+
\\
\frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} . \frac{\partial \bar s_2}{\partial \bar s_1} . \frac{\partial \bar s_1}{\partial \bar W_s}
\]</span> The General Equation is <span class="math display">\[
\frac{\partial E_N}{\partial W_s} = \sum_{i=1}^N\frac{\partial E_N}{\partial \bar y_N}. \frac{\partial \bar y_N}{\partial \bar s_i} . \frac{\partial \bar s_i}{\partial \bar W_s}
\]</span></p>
</section>
<section id="backprop-for-w_x" class="level2">
<h2 class="anchored" data-anchor-id="backprop-for-w_x">Backprop for <span class="math inline">\(W_x\)</span></h2>
<p>At time step t=3 the gradient contribution for <span class="math display">\[ \bar s_3\]</span> is <span class="math display">\[
\frac{\partial E_3}{\partial W_x} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial  W_x}
\]</span> At time step t=2 the gradient contribution for <span class="math display">\[ \bar s_2\]</span> is <span class="math display">\[
\frac{\partial E_3}{\partial W_x} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} .\frac{\partial \bar s_2}{\partial  W_x}
\]</span> At time step t=1 the gradient contribution for <span class="math display">\[ \bar s_1\]</span> is <span class="math display">\[
\frac{\partial E_3}{\partial W_x} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} . \frac{\partial \bar s_2}{\partial \bar s_1} . \frac{\partial \bar s_1}{\partial W_x}
\]</span> After considering the contributions from all three states: <span class="math display">\[\bar{s_3}\]</span> ,<span class="math display">\[\bar{s_2}\]</span> and <span class="math display">\[\bar{s_1}\]</span>, we will <strong>accumulate</strong> them to find the final gradient calculation.</p>
<p>The following equation is the gradient contributing to the adjustment of <span class="math display">\[W_s\]</span> using <strong>Backpropagation Through Time</strong>: <span class="math display">\[
\frac{\partial E_3}{\partial W_x} = \frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial  W_x}+
\\
\frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} .\frac{\partial \bar s_2}{\partial  W_x}
+
\\
\frac{\partial E_3}{\partial \bar y_3}. \frac{\partial \bar y_3}{\partial \bar s_3} . \frac{\partial \bar s_3}{\partial \bar s_2} . \frac{\partial \bar s_2}{\partial \bar s_1} . \frac{\partial \bar s_1}{\partial W_x}
\]</span> The General Equation is <span class="math display">\[
\frac{\partial E_N}{\partial W_x} = \sum_{i=1}^N\frac{\partial E_N}{\partial \bar y_N}. \frac{\partial \bar y_N}{\partial \bar s_i} . \frac{\partial \bar s_i}{\partial \bar W_x}
\]</span> RNNs have a short memory and suffers from vanishing gradient problem.</p>
</section>
</section>
<section id="vanishing-gradient" class="level1">
<h1>Vanishing Gradient</h1>
<p>In BPTT, computing the gradient with respect to hidden state involves many factors of Whh, which might result in either of the following: 1. Exploding gradient (when gradient values &gt; 1<br> <u>Solution</u><br> 1. Clipping the gradient values between a certain range 2. Vanishing gradient(when gradient values &lt;1)<br> <u>Solution</u><br> 1. Better Activation Function 2. Better Weight initialization 3. Better Network Architecture</p>
</section>
<section id="long-short-term-memory-lstm-network---generalized-version-of-gru" class="level1">
<h1>Long Short-Term Memory (LSTM) network - Generalized version of GRU</h1>
<p><img src="images/lstm.png" class="img-fluid"></p>
<section id="forget-gate" class="level2">
<h2 class="anchored" data-anchor-id="forget-gate">- Forget gate</h2>
<p>For the sake of this illustration, lets assume we are reading words in a piece of text, and want use an LSTM to keep track of grammatical structures, such as whether the subject is singular or plural. If the subject changes from a singular word to a plural word, we need to find a way to get rid of our previously stored memory value of the singular/plural state. In an LSTM, the forget gate lets us do this:</p>
<p><span class="math display">\[\Gamma_f^{\langle t \rangle} = \sigma(W_f[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_f)\tag{1} \]</span></p>
<p>Here, <span class="math inline">\(W_f\)</span> are weights that govern the forget gate’s behavior. We concatenate <span class="math inline">\([a^{\langle t-1 \rangle}, x^{\langle t \rangle}]\)</span> and multiply by <span class="math inline">\(W_f\)</span>. The equation above results in a vector <span class="math inline">\(\Gamma_f^{\langle t \rangle}\)</span> with values between 0 and 1. This forget gate vector will be multiplied element-wise by the previous cell state <span class="math inline">\(c^{\langle t-1 \rangle}\)</span>. So if one of the values of <span class="math inline">\(\Gamma_f^{\langle t \rangle}\)</span> is 0 (or close to 0) then it means that the LSTM should remove that piece of information (e.g.&nbsp;the singular subject) in the corresponding component of <span class="math inline">\(c^{\langle t-1 \rangle}\)</span>. If one of the values is 1, then it will keep the information.</p>
</section>
<section id="update-gate" class="level2">
<h2 class="anchored" data-anchor-id="update-gate">- Update gate</h2>
<p>Once we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Here is the formulat for the update gate:</p>
<p><span class="math display">\[\Gamma_u^{\langle t \rangle} = \sigma(W_u[a^{\langle t-1 \rangle}, x^{\{t\}}] + b_u)\tag{2} \]</span></p>
<p>Similar to the forget gate, here <span class="math inline">\(\Gamma_u^{\langle t \rangle}\)</span> is again a vector of values between 0 and 1. This will be multiplied element-wise with <span class="math inline">\(\tilde{c}^{\langle t \rangle}\)</span>, in order to compute <span class="math inline">\(c^{\langle t \rangle}\)</span>.</p>
</section>
<section id="updating-the-cell" class="level2">
<h2 class="anchored" data-anchor-id="updating-the-cell">- Updating the cell</h2>
<p>To update the new subject we need to create a new vector of numbers that we can add to our previous cell state. The equation we use is:</p>
<p><span class="math display">\[ \tilde{c}^{\langle t \rangle} = \tanh(W_c[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_c)\tag{3} \]</span></p>
<p>Finally, the new cell state is:</p>
<p><span class="math display">\[ c^{\langle t \rangle} = \Gamma_f^{\langle t \rangle}* c^{\langle t-1 \rangle} + \Gamma_u^{\langle t \rangle} *\tilde{c}^{\langle t \rangle} \tag{4} \]</span></p>
</section>
<section id="output-gate" class="level2">
<h2 class="anchored" data-anchor-id="output-gate">- Output gate</h2>
<p>To decide which outputs we will use, we will use the following two formulas:</p>
<p><span class="math display">\[ \Gamma_o^{\langle t \rangle}=  \sigma(W_o[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_o)\tag{5}\]</span> <span class="math display">\[ a^{\langle t \rangle} = \Gamma_o^{\langle t \rangle}* \tanh(c^{\langle t \rangle})\tag{6} \]</span></p>
<p>Where in equation 5 you decide what to output using a sigmoid function and in equation 6 you multiply that by the <span class="math inline">\(\tanh\)</span> of the previous state.</p>
<p><strong>To summarize :</strong> 1. Forget gate : Need to forget irrelevant parts of the previous state 2. Update Gate: Process current input and previous state to update cell state(c(t-1) to c(t)) 3. Updating the cell: Store relevant new information to cell state 4. Output gate : To output certain parts of cell state</p>
</section>
</section>
<section id="time-to-code--lstm-cell" class="level1">
<h1>Time to Code -LSTM Cell</h1>
<p><img src="images/lstm_cell.PNG" class="img-fluid"></p>
<p><strong>What we will do</strong>: 1. Concatenate <span class="math inline">\(a^{\langle t-1 \rangle}\)</span> and <span class="math inline">\(x^{\langle t \rangle}\)</span> in a single matrix: <span class="math inline">\(concat = \begin{bmatrix} a^{\langle t-1 \rangle} \\ x^{\langle t \rangle} \end{bmatrix}\)</span> 2. Compute all the formulas 1-6. You can use <code>sigmoid()</code> (provided) and <code>np.tanh()</code>. 3. Compute the prediction <span class="math inline">\(y^{\langle t \rangle}\)</span>. You can use <code>softmax()</code> (provided).</p>
<ol type="1">
<li>A new variable C for memory cell</li>
<li>Update Gate (<span class="math inline">\(\Gamma\)</span><sub>u</sub>) - a value between 0 nd 1</li>
<li>Forget Gate (<span class="math inline">\(\Gamma\)</span><sub>f</sub>)</li>
<li>Output Gate(<span class="math inline">\(\Gamma\)</span><sub>0</sub>)</li>
</ol>
<p>C<sup>t’ </sup> =tanh( W<sub>c</sub> [ a <sup>t-1 </sup> , X <sup>t </sup> ] + b<sub>c </sub>) <br></p>
<p><span class="math inline">\(\Gamma (u)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>u </sub>[a<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>u </sup> <br></p>
<p><span class="math inline">\(\Gamma (f)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>f </sub>[a<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>u </sup> <br></p>
<p><span class="math inline">\(\Gamma (o)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>o </sub>[a<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>r </sup> <br></p>
<p>C<sup>t </sup> = <span class="math inline">\(\Gamma\)</span><sub>u</sub> * C<sup>t’ </sup> + ( 1-<span class="math inline">\(\Gamma\)</span><sub>f</sub> ) * C<sup>t-1 </sup></p>
<p>a<sub>t</sub> = <span class="math inline">\(\Gamma\)</span><sub>o</sub> * tanh C<sup>t</sup></p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:32.763926Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:32.746793Z&quot;}" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: lstm_cell_forward</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lstm_cell_forward(xt, a_prev, c_prev, parameters):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Implement a single forward step of the LSTM-cell as described in Figure (4)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">    xt -- your input data at timestep "t", numpy array of shape (n_x, m).</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">    a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m)</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">    c_prev -- Memory state at timestep "t-1", numpy array of shape (n_a, m)</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">    parameters -- python dictionary containing:</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co">                        bc --  Bias of the first "tanh", numpy array of shape (n_a, 1)</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co">                        bo --  Bias of the output gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co">                        </span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co">    a_next -- next hidden state, of shape (n_a, m)</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co">    c_next -- next memory state, of shape (n_a, m)</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co">    yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m)</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co">    cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co">    Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde),</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="co">          c stands for the memory value</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve parameters from "parameters"</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    Wf <span class="op">=</span> parameters[<span class="st">"Wf"</span>]</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    bf <span class="op">=</span> parameters[<span class="st">"bf"</span>]</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    Wi <span class="op">=</span> parameters[<span class="st">"Wi"</span>]</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    bi <span class="op">=</span> parameters[<span class="st">"bi"</span>]</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    Wc <span class="op">=</span> parameters[<span class="st">"Wc"</span>]</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    bc <span class="op">=</span> parameters[<span class="st">"bc"</span>]</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    Wo <span class="op">=</span> parameters[<span class="st">"Wo"</span>]</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    bo <span class="op">=</span> parameters[<span class="st">"bo"</span>]</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    Wy <span class="op">=</span> parameters[<span class="st">"Wy"</span>]</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    by <span class="op">=</span> parameters[<span class="st">"by"</span>]</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve dimensions from shapes of xt and Wy</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    n_x, m <span class="op">=</span> xt.shape</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    n_y, n_a <span class="op">=</span> Wy.shape</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE </span><span class="al">###</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate a_prev and xt (≈3 lines)</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>    concat <span class="op">=</span>np.zeros((n_a<span class="op">+</span>n_x,m))</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    concat[: n_a, :] <span class="op">=</span>a_prev</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>    concat[n_a :, :] <span class="op">=</span> xt</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4) (≈6 lines)</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>    ft <span class="op">=</span> sigmoid(np.dot(Wf,concat)<span class="op">+</span>bf)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    it <span class="op">=</span> sigmoid(np.dot(Wi,concat)<span class="op">+</span>bi)</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    cct <span class="op">=</span> np.tanh(np.dot(Wc,concat)<span class="op">+</span>bc)</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>    c_next <span class="op">=</span> ft<span class="op">*</span>c_prev<span class="op">+</span> it<span class="op">*</span>cct</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    ot <span class="op">=</span> sigmoid(np.dot(Wo,concat)<span class="op">+</span>bo)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>    a_next <span class="op">=</span>ot<span class="op">*</span>np.tanh(c_next)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute prediction of the LSTM cell (≈1 line)</span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>    yt_pred <span class="op">=</span> softmax(np.dot(Wy,a_next)<span class="op">+</span>by)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values needed for backward propagation in cache</span></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>    cache <span class="op">=</span> (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a_next, c_next, yt_pred, cache</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:33.981599Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:33.962934Z&quot;}" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">3</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>a_prev <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">3</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>c_prev <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">3</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>Wf <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>bf <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>Wi <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>bi <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>Wo <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>bo <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>Wc <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>bc <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>Wy <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>by <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">1</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {<span class="st">"Wf"</span>: Wf, <span class="st">"Wi"</span>: Wi, <span class="st">"Wo"</span>: Wo, <span class="st">"Wc"</span>: Wc, <span class="st">"Wy"</span>: Wy, <span class="st">"bf"</span>: bf, <span class="st">"bi"</span>: bi, <span class="st">"bo"</span>: bo, <span class="st">"bc"</span>: bc, <span class="st">"by"</span>: by}</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>a_next, c_next, yt, cache <span class="op">=</span> lstm_cell_forward(xt, a_prev, c_prev, parameters)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a_next[4] = "</span>, a_next[<span class="dv">4</span>])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a_next.shape = "</span>, c_next.shape)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"c_next[2] = "</span>, c_next[<span class="dv">2</span>])</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"c_next.shape = "</span>, c_next.shape)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"yt[1] ="</span>, yt[:,<span class="dv">1</span>])</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"yt.shape = "</span>, yt.shape)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cache[1][3] ="</span>, cache[<span class="dv">1</span>][<span class="dv">3</span>])</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"len(cache) = "</span>, <span class="bu">len</span>(cache))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a_next[4] =  [-0.10195999  0.00914244 -0.47674224]
a_next.shape =  (5, 3)
c_next[2] =  [-0.2761536  -1.10274727  0.47710894]
c_next.shape =  (5, 3)
yt[1] = [0.34166892 0.11058645 0.14684232 0.00715921 0.05455281 0.02475153
 0.02097779 0.02419735 0.1596464  0.10961722]
yt.shape =  (10, 3)
cache[1][3] = [ 0.51704028 -0.60571164  0.02549849]
len(cache) =  10</code></pre>
</div>
</div>
</section>
<section id="lstm-forward-pass" class="level1">
<h1>LSTM Forward Pass</h1>
<p>Now that we have implemented one step of an LSTM, we can now iterate this over this using a for-loop to process a sequence of <span class="math inline">\(T_x\)</span> inputs. <img src="images/lstm_fp.PNG" class="img-fluid"></p>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:37.172701Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:37.156451Z&quot;}" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: lstm_forward</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lstm_forward(x, a0, parameters):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (3).</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">    x -- Input data for every time-step, of shape (n_x, m, T_x).</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    a0 -- Initial hidden state, of shape (n_a, m)</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    parameters -- python dictionary containing:</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">                        bc -- Bias of the first "tanh", numpy array of shape (n_a, 1)</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">                        bo -- Bias of the output gate, numpy array of shape (n_a, 1)</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">                        </span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co">    y -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">    caches -- tuple of values needed for the backward pass, contains (list of all the caches, x)</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize "caches", which will track the list of all the caches</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    caches <span class="op">=</span> []</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE </span><span class="al">###</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve dimensions from shapes of x and parameters['Wy'] (≈2 lines)</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    n_x, m, T_x <span class="op">=</span>x.shape</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    n_y, n_a <span class="op">=</span> parameters[<span class="st">"Wy"</span>].shape</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initialize "a", "c" and "y" with zeros (≈3 lines)</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_a,m,T_x))</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_a,m,T_x))</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_y,m,T_x))</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a_next and c_next (≈2 lines)</span></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    a_next <span class="op">=</span> a0</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    c_next <span class="op">=</span> np.zeros(shape<span class="op">=</span>a_next.shape)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over all time-steps</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T_x):</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update next hidden state, next memory state, compute the prediction, get the cache (≈1 line)</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        a_next, c_next, yt, cache <span class="op">=</span> lstm_cell_forward(x[:,:,t],a_next,c_next,parameters)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the value of the new "next" hidden state in a (≈1 line)</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>        a[:,:,t] <span class="op">=</span> a_next</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the value of the prediction in y (≈1 line)</span></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        y[:,:,t] <span class="op">=</span> yt</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save the value of the next cell state (≈1 line)</span></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>        c[:,:,t]  <span class="op">=</span> c_next</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the cache into caches (≈1 line)</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>        caches.append(cache)</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values needed for backward propagation in cache</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>    caches <span class="op">=</span> (caches, x)</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a, y, c, caches</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2019-06-17T17:07:38.010071Z&quot;,&quot;start_time&quot;:&quot;2019-06-17T17:07:37.988457Z&quot;}" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">3</span>,<span class="dv">7</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>a0 <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">3</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>Wf <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>bf <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>Wi <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>bi <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>Wo <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>bo <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>Wc <span class="op">=</span> np.random.randn(<span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>bc <span class="op">=</span> np.random.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>Wy <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>by <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">1</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {<span class="st">"Wf"</span>: Wf, <span class="st">"Wi"</span>: Wi, <span class="st">"Wo"</span>: Wo, <span class="st">"Wc"</span>: Wc, <span class="st">"Wy"</span>: Wy, <span class="st">"bf"</span>: bf, <span class="st">"bi"</span>: bi, <span class="st">"bo"</span>: bo, <span class="st">"bc"</span>: bc, <span class="st">"by"</span>: by}</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>a, y, c, caches <span class="op">=</span> lstm_forward(x, a0, parameters)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"a.shape = "</span>, a.shape)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y[1] ="</span>, y[:,<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y.shape = "</span>, y.shape)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"caches[1][1[1]] ="</span>, caches[<span class="dv">1</span>][<span class="dv">1</span>][<span class="dv">1</span>])</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"c[1][2][1]"</span>, c[<span class="dv">1</span>][<span class="dv">2</span>][<span class="dv">1</span>])</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"len(caches) = "</span>, <span class="bu">len</span>(caches))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a.shape =  (5, 3, 7)
y[1] = [0.31913833 0.09499694 0.07833096 0.02950319 0.1547548  0.02714568
 0.11487035 0.04371666 0.11982581 0.01771727]
y.shape =  (10, 3, 7)
caches[1][1[1]] = [-0.26788808  0.53035547 -0.69166075 -0.39675353 -0.6871727  -0.84520564
 -0.67124613]
c[1][2][1] 0.15137211713431287
len(caches) =  2</code></pre>
</div>
</div>
</section>
<section id="gru-simplified" class="level1">
<h1>GRU Simplified</h1>
<p><a href="https://arxiv.org/abs/1409.1259">On the properties of neural machine translation: Encoder Decoder Approaches</a> <br> <a href="https://arxiv.org/abs/1412.3555">Empirical Evalaution of Gated Recurrent Neural Networks on Sequence Modeling</a></p>
<ol type="1">
<li>A new variable C for memory cell</li>
<li>Update Gate (<span class="math inline">\(\Gamma\)</span><sub>u</sub>) - a value between 0 nd 1</li>
</ol>
<p>C<sup>t </sup> = a<sup>t</sup> <br></p>
<p>C<sup>t’ </sup> =tanh( W<sub>c</sub> [ C <sup>t-1 </sup> , X <sup>t </sup> ] + b<sup>c </sup>) <br></p>
<p><span class="math inline">\(\Gamma (u)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>u </sub>[C<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>u </sup> <br></p>
<p>C<sup>t </sup> = <span class="math inline">\(\Gamma\)</span> * C<sup>t’ </sup> + 1-<span class="math inline">\(\Gamma\)</span> * C<sup>t-1 </sup></p>
<p><img src="images/gru_cell.png" class="img-fluid"></p>
</section>
<section id="gru-full" class="level1">
<h1>GRU Full</h1>
<ol type="1">
<li>A new variable C for memory cell</li>
<li>Update Gate (<span class="math inline">\(\Gamma\)</span><sub>u</sub>) - a value between 0 nd 1</li>
<li>Relevant Gate(<span class="math inline">\(\Gamma\)</span><sub>r</sub>)</li>
</ol>
<p>C<sup>t’ </sup> =tanh( W<sub>c</sub> [ <span class="math inline">\(\Gamma\)</span><sub>r</sub> * C <sup>t-1 </sup> , X <sup>t </sup> ] + b<sup>c </sup>) <br></p>
<p><span class="math inline">\(\Gamma (u)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>u </sub>[C<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>u </sup> <br></p>
<p><span class="math inline">\(\Gamma (r)\)</span> = <span class="math inline">\(\sigma\)</span>(W<sub>r </sub>[C<sup>t-1 </sup> , X<sup>t </sup>] + b <sup>r </sup> <br></p>
<p>C<sup>t </sup> = <span class="math inline">\(\Gamma\)</span><sub>u</sub> * C<sup>t’ </sup> + ( 1-<span class="math inline">\(\Gamma\)</span><sub>u</sub> ) * C<sup>t-1 </sup></p>
<section id="thank-you" class="level2">
<h2 class="anchored" data-anchor-id="thank-you">Thank you</h2>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/aman5319\.github\.io\/portfolio\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aman5319/portfolio" data-repo-id="R_kgDOJ44pkw" data-category="Q&amp;A" data-category-id="DIC_kwDOJ44pk84CXwVt" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../posts/NLP/nlp_overview.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">NLP Overview</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../posts/Optimization/optimisers_in_dl.html" class="pagination-link">
        <span class="nav-page-text">Optimizers in - Deep Learning</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Blog made with 💜 and <a href="https://quarto.org/">Quarto</a>, by Aman Pandey. License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:amanpandey@mailfence.com">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>