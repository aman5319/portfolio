<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aman Pandey">
<meta name="dcterms.date" content="2019-10-08">
<meta name="description" content="What is NLP, what problems does it solve and components within it.">

<title>NLP Overview – Aman Pandey</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-3a01e2046221230fdceeea94b1ec5d67.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-a4a11d514c7d463668e07712114998e6.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-2d7b555c8139e1218026ae7dd17bce4a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="NLP Overview – Aman Pandey">
<meta property="og:description" content="What is NLP, what problems does it solve and components within it.">
<meta property="og:image" content="https://uc-r.github.io/public/images/analytics/feature-engineering/bow-image.png">
<meta property="og:site_name" content="Aman Pandey">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Aman Pandey</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../tech_blogs"> 
<span class="menu-text">Tech Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../non_tech_blogs"> 
<span class="menu-text">Non Tech Blogs</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">NLP Overview</h1>
                  <div>
        <div class="description">
          What is NLP, what problems does it solve and components within it.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep-learning</div>
                <div class="quarto-category">nlp</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Aman Pandey </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 8, 2019</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-nlp" id="toc-what-is-nlp" class="nav-link active" data-scroll-target="#what-is-nlp">What is NLP?</a>
  <ul class="collapse">
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection">Data Collection</a>
  <ul class="collapse">
  <li><a href="#sources" id="toc-sources" class="nav-link" data-scroll-target="#sources">Sources</a></li>
  <li><a href="#for-vernacular-text" id="toc-for-vernacular-text" class="nav-link" data-scroll-target="#for-vernacular-text">For Vernacular text</a></li>
  <li><a href="#tools" id="toc-tools" class="nav-link" data-scroll-target="#tools">Tools</a></li>
  <li><a href="#data-annotation-tool" id="toc-data-annotation-tool" class="nav-link" data-scroll-target="#data-annotation-tool">Data Annotation Tool</a></li>
  </ul></li>
  <li><a href="#some-common-packages" id="toc-some-common-packages" class="nav-link" data-scroll-target="#some-common-packages">Some Common Packages</a>
  <ul class="collapse">
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data preprocessing</a></li>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a></li>
  <li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection">Feature Selection</a></li>
  <li><a href="#text-vectorization" id="toc-text-vectorization" class="nav-link" data-scroll-target="#text-vectorization">Text Vectorization</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  <li><a href="#architectures" id="toc-architectures" class="nav-link" data-scroll-target="#architectures">Architectures</a></li>
  </ul></li>
  <li><a href="#important-topics-that-have-shaped-nlp" id="toc-important-topics-that-have-shaped-nlp" class="nav-link" data-scroll-target="#important-topics-that-have-shaped-nlp">Important topics that have shaped NLP</a>
  <ul class="collapse">
  <li><a href="#grounding" id="toc-grounding" class="nav-link" data-scroll-target="#grounding">Grounding</a></li>
  <li><a href="#nli-natural-language-inference" id="toc-nli-natural-language-inference" class="nav-link" data-scroll-target="#nli-natural-language-inference">NLI (Natural Language Inference)</a></li>
  <li><a href="#coreference-resolution" id="toc-coreference-resolution" class="nav-link" data-scroll-target="#coreference-resolution">Coreference resolution</a></li>
  <li><a href="#constituency-parsing-and-dependency-parsing" id="toc-constituency-parsing-and-dependency-parsing" class="nav-link" data-scroll-target="#constituency-parsing-and-dependency-parsing">Constituency parsing and Dependency parsing</a></li>
  <li><a href="#semantic-parsing" id="toc-semantic-parsing" class="nav-link" data-scroll-target="#semantic-parsing">Semantic Parsing</a></li>
  <li><a href="#machine-translation" id="toc-machine-translation" class="nav-link" data-scroll-target="#machine-translation">Machine Translation</a></li>
  </ul></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">Thank you</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/aman5319/portfolio/blob/main/tech_blogs/NLP/nlp_overview.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/aman5319/portfolio/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="what-is-nlp" class="level1">
<h1>What is NLP?</h1>
<pre><code>NLP stands for Natural Language Processing, which is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and human language. NLP encompasses the development of algorithms, models, and techniques that enable computers to understand, interpret, and generate human language in a valuable way. Here are some key aspects of NLP:    </code></pre>
<p>NLP is Classified in two sub-categories</p>
<ol type="1">
<li><code>NLU</code> (Natural Language Understanding) - NLU is about teaching machines to understand what humans are saying. It includes task like Semantic Parsing, Relation Extraction, Natural Language Inference, Word Sense Disambiguation. <br><br></li>
<li><code>NLG</code> (Natural Language Generation) - NLG is about teaching machines to generate human-like text or speech. It includes tasks like language translation, text generation, and text summarization, where the machine generates text that sounds natural to humans.</li>
</ol>
<p>Variety of Task under NLP:</p>
<pre><code>1.  Part-of-speech tagging: identify if each word is a noun, verb, adjective, etc.)
2.  Named entity recognition NER): identify person names, organizations, locations, medical codes, time expressions, quantities, monetary values, etc)
3.  Question answering
4.  Speech recognition
5.  Text-to-speech and Speech-to-text
6.  Topic modeling
7.  Sentiment classification
9.  Language modeling
10. Translation
11. Intent Recognition
12. Semantic Parsing
13. Co-reference Resolution and Dependency Parsing
14. Summarization 
15. Chatbots etc.
16.  Text Classification
17.  Topic Modeling
18. Image Captioning
19. Optical Character Recognition
20. Visual Question Answering</code></pre>
<p><img src="images/1.png" class="img-fluid"></p>
<section id="data-collection" class="level2">
<h2 class="anchored" data-anchor-id="data-collection">Data Collection</h2>
<section id="sources" class="level3">
<h3 class="anchored" data-anchor-id="sources">Sources</h3>
<p>For <code>Generative Training</code> :- Where the model has to learn about the data and its distribution</p>
<pre><code>1. News Article:- Archives
2. Wikipedia Article 
3. Book Corpus 
4. Crawling the Internet for webpages.
5. Social Media - Reddit, Stackoverflow, twitter
6. Handcrafted Datasets.</code></pre>
<p>Generative training on an abundant set of unsupervised data helps in performing Transfer learning for a downstream task where few parameters need to be learnt from sratch and less data is also required.</p>
<p>For <code>Determinstic Training</code> :- Where the model learns about Decision boundary within the data.</p>
<pre><code>Generic
    1. Kaggle Dataset
Sentiment
    1. Product Reviews :- Amazon, Flipkart
Emotion:-
    1. ISEAR
    2. Twitter dataset
Question Answering:-
    1. SQUAD
Different task has different Handcrafted data.</code></pre>
</section>
<section id="for-vernacular-text" class="level3">
<h3 class="anchored" data-anchor-id="for-vernacular-text">For Vernacular text</h3>
<p>In vernacular context we have crisis in data especially when it comes to state specific language in India. (Ex. Bengali, Gujurati etc.) Few Sources are:- 1. News (Jagran.com, Danik bhaskar) 2. Moview reviews (Web Duniya) 3. Hindi Wikipedia 4. Book Corpus 6. IIT Bombay (English-Hindi Parallel Corpus)</p>
</section>
<section id="tools" class="level3">
<h3 class="anchored" data-anchor-id="tools">Tools</h3>
<ol type="1">
<li>Scrapy :- Simple, Extensible framework for scraping and crawling websites. Has numerous feature into it.</li>
<li>Beautiful-Soup :- For Parsing Html and xml documents.</li>
<li>Excel</li>
<li>wikiextractor:- A tool for extracting plain text from Wikipedia dumps</li>
</ol>
</section>
<section id="data-annotation-tool" class="level3">
<h3 class="anchored" data-anchor-id="data-annotation-tool">Data Annotation Tool</h3>
<ol type="1">
<li>TagTog</li>
<li>Prodigy (Explosion AI)</li>
<li>Mechanical Turk</li>
<li>PyBossa</li>
<li>Chakki-works Doccano<br>
</li>
<li>WebAnno</li>
<li>Brat</li>
<li>Label Studio</li>
</ol>
</section>
</section>
<section id="some-common-packages" class="level2">
<h2 class="anchored" data-anchor-id="some-common-packages">Some Common Packages</h2>
<ol type="1">
<li><a href="https://github.com/zalandoresearch/flair">Flair</a></li>
<li><a href="https://github.com/allenai/allennlp">Allen NLP</a></li>
<li><a href="https://github.com/deepmipt/deeppavlov">Deep Pavlov</a></li>
<li><a href="https://github.com/facebookresearch/PyText">Pytext</a></li>
<li><a href="https://www.nltk.org/">NLTK</a></li>
<li><a href="https://github.com/huggingface/transformers">Transformer</a></li>
<li><a href="https://spacy.io/">Spacy</a></li>
<li><a href="https://torchtext.readthedocs.io/en/latest/">torchtext</a></li>
<li><a href="https://github.com/cbaziotis/ekphrasis">Ekphrasis</a></li>
<li><a href="https://radimrehurek.com/gensim/">Genism</a></li>
<li><a href="https://github.com/stanfordnlp/stanza">Stanza</a></li>
<li><a href="https://github.com/JohnSnowLabs/spark-nlp">Spark-NLP</a></li>
</ol>
<p>Any NLP task has to have few important components. 1. Data Pre-processing (Basically Junk removal from text) 2. Tokenization 3. Feature Selection 4. Token Vectorization 4. Model Building 5. Training and Inference.</p>
<section id="data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing">Data preprocessing</h3>
<p>Data preprocessing is a crucial step in natural language processing (NLP) that involves cleaning and transforming raw text data into a format that can be effectively used for NLP tasks. Here is a list of common NLP data preprocessing techniques:</p>
<ol type="1">
<li><p><strong>Tokenization:</strong> Splitting the text into individual words or tokens. Tokenization is the foundation for many NLP tasks.</p></li>
<li><p><strong>Lowercasing:</strong> Converting all text to lowercase to ensure uniformity and simplify analysis by treating words in a case-insensitive manner.</p></li>
<li><p><strong>Stop Word Removal:</strong> Removing common words (e.g., “and,” “the,” “in”) that don’t carry much meaning and are often filtered out to reduce noise.</p></li>
<li><p><strong>Punctuation Removal:</strong> Stripping punctuation marks from text to focus on the actual words.</p></li>
<li><p><strong>Special Character Removal:</strong> Removing special characters or symbols that may not be relevant to the analysis.</p></li>
<li><p><strong>Whitespace Trimming:</strong> Removing extra spaces or leading/trailing spaces.</p></li>
<li><p><strong>HTML Tag Removal:</strong> When dealing with web data, removing HTML tags that may be present in the text.</p></li>
<li><p><strong>Stemming:</strong> Reducing words to their root or base form. For example, “running” and “ran” would both be stemmed to “run.”</p></li>
<li><p><strong>Lemmatization:</strong> Similar to stemming but reduces words to their dictionary or lemma form, which often results in a more linguistically accurate word.</p></li>
<li><p><strong>Spell Checking:</strong> Correcting spelling errors in the text to improve the quality of the data.</p></li>
<li><p><strong>Text Normalization:</strong> Ensuring consistent representations for words, like converting abbreviations to their full form (e.g., “don’t” to “do not”).</p></li>
<li><p><strong>Handling Contractions:</strong> Expanding contractions (e.g., “can’t” to “cannot”) for better analysis.</p></li>
<li><p><strong>Handling Acronyms:</strong> Expanding acronyms (e.g., “NLP” to “natural language processing”) for clarity.</p></li>
<li><p><strong>Noise Removal:</strong> Eliminating irrelevant or noisy data, such as non-textual content or metadata.</p></li>
<li><p><strong>Token Filtering:</strong> Filtering tokens based on specific criteria (e.g., length, frequency) to remove outliers or less meaningful words.</p></li>
<li><p><strong>Text Chunking:</strong> Dividing text into smaller chunks or sentences for analysis.</p></li>
<li><p><strong>Handling Missing Data:</strong> Dealing with missing values or incomplete text data.</p></li>
<li><p><strong>Removing Duplicates:</strong> Identifying and removing duplicate or near-duplicate text entries.</p></li>
</ol>
</section>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>Tokenization is the process of breaking down a text or a sequence of characters into smaller units, typically words or subwords, which are called tokens.</p>
<p>The primary purpose of tokenization is to split text into units that can be processed more easily. These units are the basic building blocks for various NLP tasks. Here are some key points about tokenization:</p>
<p><code>Token</code>: A token is a single unit or word that results from the tokenization process. For example, the sentence “I love NLP” can be tokenized into three tokens: “I,” “love,” and “NLP.”</p>
<p><code>Word Tokenization</code>: Word tokenization involves splitting text into words. In many cases, words are separated by whitespace or punctuation. Word tokenization is a common approach for many NLP tasks.</p>
<p><code>Subword Tokenization</code>: Subword tokenization splits text into smaller units, which are often subword parts or characters. This approach is used in models like BERT, which can capture the meaning of subwords and handle out-of-vocabulary words effectively.</p>
<p><code>Sentence Tokenization</code>: Sentence tokenization divides text into individual sentences. It is used to process and analyze text at the sentence level.</p>
</section>
<section id="feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection">Feature Selection</h3>
<p>From Tokens features are created 1. <strong>N-grams:</strong> Extracting multi-word phrases (n-grams) to capture more context (e.g., “natural language processing” as a bigram).</p>
<ol start="2" type="1">
<li><p><strong>Entity Recognition:</strong> Identifying and labeling entities (e.g., names of people, organizations, locations) in the text.</p></li>
<li><p><strong>Part-of-Speech Tagging:</strong> Assigning parts of speech (e.g., noun, verb, adjective) to words in the text.</p></li>
<li><p><strong>Encoding/Decoding:</strong> Converting text into numerical representations, such as one-hot encoding or word embeddings, and vice versa.</p></li>
</ol>
</section>
<section id="text-vectorization" class="level3">
<h3 class="anchored" data-anchor-id="text-vectorization">Text Vectorization</h3>
<ol type="1">
<li><p><code>Bag of Words</code> <img src="https://uc-r.github.io/public/images/analytics/feature-engineering/bow-image.png" class="img-fluid"></p></li>
<li><p><code>TF-IDF</code> <img src="https://miro.medium.com/max/3604/1*ImQJjYGLq2GE4eX40Mh28Q.png" class="img-fluid"></p></li>
</ol>
<p>Representation of Text for Sequence Task</p>
<pre><code>Every text in a sentence is represented using one hector vector based on its position in the vocabulary</code></pre>
<p><img src="https://cdn-images-1.medium.com/max/1200/1*YEJf9BQQh0ma1ECs6x_7yQ.png" class="img-fluid"></p>
<ol start="3" type="1">
<li><code>Word Embeddings</code></li>
</ol>
<p>BOW and TF-IDF are spare representation of Tokens. In contrast Embedding refer to dense vector representations of Tokens in a continuous vector space. These embeddings are used to represent words or other linguistic units in a way that captures semantic relationships and contextual information.</p>
<p>Embeddings are a fundamental component of many NLP applications, enabling models to understand and work with textual data in a way that captures semantic information and relationships between words. They have revolutionized the field of NLP and have significantly improved the performance of various NLP tasks.</p>
<pre><code>1. Word2Vec
2. Glove
3. FastText        
4. ELMO</code></pre>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">Models</h3>
<ol type="1">
<li>RNN</li>
<li>LSTM</li>
<li>BI-LSTM</li>
<li>GRU</li>
<li>CNNs</li>
</ol>
</section>
<section id="architectures" class="level3">
<h3 class="anchored" data-anchor-id="architectures">Architectures</h3>
<ol type="1">
<li><p>Seq-Seq</p></li>
<li><p>Seq-Seq Attention</p></li>
<li><p>Pointer Generator Network</p></li>
<li><p>Transformer</p></li>
<li><p>GPT</p></li>
<li><p>Transformer-XL</p></li>
<li><p>BERT</p></li>
<li><p>GPT-2</p></li>
</ol>
</section>
</section>
<section id="important-topics-that-have-shaped-nlp" class="level2">
<h2 class="anchored" data-anchor-id="important-topics-that-have-shaped-nlp">Important topics that have shaped NLP</h2>
<section id="grounding" class="level3">
<h3 class="anchored" data-anchor-id="grounding">Grounding</h3>
<p>Grounding refers to the process of connecting or mapping natural language expressions to their corresponding real-world entities or concepts. It is a fundamental aspect of NLU systems, which aim to bridge the gap between human language and the world’s knowledge and objects. Grounding allows NLU systems to understand and interpret language in a way that aligns with the physical and conceptual world.</p>
<p>There are several forms of grounding in NLU:</p>
<ol type="1">
<li><p><strong>Referential Grounding</strong>: This involves linking words or phrases in natural language to specific entities in the real world. For example, in the sentence “The Eiffel Tower is a famous landmark,” referential grounding would involve identifying “the Eiffel Tower” as a reference to the actual structure in Paris.</p></li>
<li><p><strong>Spatial Grounding</strong>: This is about understanding the spatial relationships and locations described in language. For instance, when someone says, “The cat is on the table,” spatial grounding would involve identifying the cat’s location relative to the table.</p></li>
<li><p><strong>Temporal Grounding</strong>: This involves relating language to time. For example, understanding phrases like “tomorrow,” “last week,” or “in the future” and connecting them to specific points in time.</p></li>
<li><p><strong>Ontological Grounding</strong>: This is about mapping language to a structured knowledge representation or ontology. For instance, understanding that “apple” can refer to both the fruit and the technology company and distinguishing between them based on the context.</p></li>
<li><p><strong>Semantic Grounding</strong>: This relates to understanding the meaning of words and phrases in a semantic context. It involves recognizing word sense disambiguation, word sense induction, and other techniques for interpreting the meaning of words within the given context.</p></li>
</ol>
</section>
<section id="nli-natural-language-inference" class="level3">
<h3 class="anchored" data-anchor-id="nli-natural-language-inference">NLI (Natural Language Inference)</h3>
<p>Natural Language Inference, which is a fundamental task in natural language understanding (NLU). It involves determining the relationship between two given sentences: a “premise” and a “hypothesis.” The goal is to determine whether the hypothesis is entailed, contradicted, or neutral with respect to the information presented in the premise. NLI is crucial for various NLU applications, including question answering, text summarization, sentiment analysis, and more.</p>
<p>Two widely recognized datasets for NLI are SNLI (Stanford Natural Language Inference) and MultiNLI. These datasets are used for training and evaluating NLI models:</p>
<ol type="1">
<li>SNLI (Stanford Natural Language Inference):
<ul>
<li>SNLI is one of the pioneering datasets for NLI. It contains a collection of sentence pairs labeled with one of three categories: “entailment,” “contradiction,” or “neutral.”</li>
<li>The dataset consists of sentences that are manually generated and crowd-sourced annotations to provide labels.</li>
</ul></li>
<li>MultiNLI (The Multi-Genre Natural Language Inference Corpus):
<ul>
<li>MultiNLI is an extension of SNLI and is designed to be more challenging. It contains sentence pairs from various genres, which helps NLI models generalize better across different text types and styles.</li>
<li>It offers a more diverse set of language samples, making it a valuable resource for NLI research.</li>
</ul></li>
</ol>
<p>Examples of NLI tasks include:</p>
<ul>
<li>Given the premise “The cat is sitting on the windowsill” and the hypothesis “A feline is resting near the window,” the NLI model should determine that the hypothesis entails the premise (entailment).</li>
<li>For the premise “The dog is chasing the mailman,” and the hypothesis “The mailman is chasing the dog,” the model should recognize that the hypothesis contradicts the premise (contradiction).</li>
<li>If the premise is “The sun is shining brightly,” and the hypothesis is “The weather is beautiful,” the NLI model should indicate that the hypothesis is neutral with respect to the premise (neutral).</li>
</ul>
<p>NLI is an essential benchmark for evaluating the performance of NLU models, as it assesses their ability to comprehend and reason about the relationships between sentences, which is crucial for various natural language understanding tasks.</p>
</section>
<section id="coreference-resolution" class="level3">
<h3 class="anchored" data-anchor-id="coreference-resolution">Coreference resolution</h3>
<p>Coreference resolution is a natural language processing (NLP) task that involves determining when two or more expressions (words or phrases) in a text refer to the same entity or concept. The primary goal of co-reference resolution is to identify which words or phrases in a text are related to one another in terms of their reference to a common entity, such as a person, place, or thing. This task is crucial for understanding the structure and meaning of text, as it helps in creating coherent and cohesive interpretations of documents.</p>
<p>Here’s a breakdown of coreference resolution and its importance:</p>
<ol type="1">
<li><strong>Definition of Coreference Resolution</strong>:
<ul>
<li>Co-reference resolution involves identifying co-referent expressions. For example, in the sentence “John said he was tired,” the pronoun “he” co-refers to “John.”</li>
<li>It can be applied to different types of expressions, including pronouns (he, she, it), definite noun phrases (the cat, this book), and indefinite noun phrases (a dog, some people).</li>
</ul></li>
<li><strong>Different Datasets</strong>:
<ul>
<li>There are several datasets used for training and evaluating coreference resolution models. Some popular datasets include:
<ul>
<li><strong>OntoNotes</strong>: A widely used dataset that provides text documents with annotations for coreference resolution.</li>
<li><strong>CoNLL-2012</strong>: Part of the CoNLL Shared Task series, this dataset contains news articles with annotated coreferences.</li>
<li><strong>ACE</strong>: The Automatic Content Extraction (ACE) program includes a dataset for entity coreference, which is widely used for evaluation.</li>
<li><strong>Web Anaphora Corpus</strong>: This dataset includes web documents and their coreference annotations.</li>
</ul></li>
</ul></li>
<li><strong>Importance of Coreference Resolution</strong>:
<ul>
<li><strong>Text Coherence</strong>: Coreference resolution helps in maintaining text coherence by ensuring that different mentions of the same entity are connected correctly. It makes the text easier to understand and follow.</li>
<li><strong>Information Extraction</strong>: In information extraction tasks, such as named entity recognition and relation extraction, it is essential to know which entities are being referred to in a text to extract relevant information.</li>
<li><strong>Question Answering</strong>: In question-answering systems, resolving co-references is crucial to understand and answer questions correctly.</li>
<li><strong>Summarization</strong>: In text summarization, identifying coreferences is necessary to produce coherent and concise summaries.</li>
</ul></li>
<li><strong>Examples</strong>:
<ul>
<li>In a news article, coreference resolution is used to determine that “President Obama” and “he” refer to the same person.</li>
<li>In a chatbot application, coreference resolution helps the bot understand that “it” in “I bought a new phone. It has a great camera” refers to the phone.</li>
<li>In an academic paper, coreference resolution helps in identifying that “the study” and “the research” refer to the same research project.</li>
</ul></li>
</ol>
<p>coreference resolution is a crucial task in NLP that plays a significant role in various applications, including machine translation, sentiment analysis, and information retrieval, as it enables a more accurate and coherent understanding of text.</p>
</section>
<section id="constituency-parsing-and-dependency-parsing" class="level3">
<h3 class="anchored" data-anchor-id="constituency-parsing-and-dependency-parsing">Constituency parsing and Dependency parsing</h3>
<p>Constituency parsing and dependency parsing are two common techniques in natural language processing (NLP) used to analyze the grammatical structure of sentences in a language. They help in understanding the relationships between words in a sentence, which is crucial for various NLP tasks such as machine translation, information extraction, and sentiment analysis.</p>
<ol type="1">
<li><p><strong>Constituency Parsing</strong>:</p>
<ul>
<li><p><strong>Definition</strong>: Constituency parsing, also known as phrase structure parsing, involves breaking down a sentence into smaller constituents (phrases) based on a predefined grammar, typically represented using a context-free grammar (CFG). It organizes words into hierarchical structures, with phrases contained within other phrases.</p></li>
<li><p><strong>Datasets</strong>: Constituency parsing typically uses datasets like the Penn Treebank, which contains sentences annotated with parse trees in a context-free grammar format.</p></li>
<li><p><strong>Importance</strong>: Constituency parsing provides a hierarchical representation of a sentence, which is helpful for syntactic analysis and understanding the grammatical relationships between words. This is essential for tasks like text generation, grammar correction, and summarization.</p></li>
<li><p><strong>Example</strong>:</p>
<p>Sentence: “The quick brown fox jumps over the lazy dog.”</p>
<p>Parse Tree:</p>
<pre><code>(S
  (NP (DT The) (JJ quick) (JJ brown) (NN fox))
  (VP (VBZ jumps)
    (PP (IN over)
      (NP (DT the) (JJ lazy) (NN dog))))
)</code></pre></li>
</ul></li>
<li><p><strong>Dependency Parsing</strong>:</p>
<ul>
<li><p><strong>Definition</strong>: Dependency parsing focuses on capturing the grammatical relationships between words in a sentence in terms of directed links (dependencies). Each word is associated with a head word to which it is syntactically related. This results in a tree structure where words are nodes, and dependencies are edges.</p></li>
<li><p><strong>Datasets</strong>: Dependency parsing uses datasets like the Universal Dependencies Project, which contains sentences annotated with dependency trees.</p></li>
<li><p><strong>Importance</strong>: Dependency parsing is valuable for tasks like information extraction, named entity recognition, and machine translation. It provides a more direct representation of the syntactic structure and word relationships in a sentence.</p></li>
<li><p><strong>Example</strong>:</p>
<p>Sentence: “The quick brown fox jumps over the lazy dog.”</p>
<p>Dependency Tree:</p>
<pre><code>jumps(ROOT-0, jumps-4)
├── fox(nsubj-4, fox-3)
│   ├── The(det-1, The-0)
│   ├── quick(amod-2, quick-1)
│   └── brown(amod-3, brown-2)
├── dog(nmod-4, dog-7)
│   ├── over(case-6, over-5)
│   └── lazy(amod-7, lazy-6)
│       └── The(det-1, The-0)</code></pre></li>
</ul></li>
</ol>
<p>constituency parsing and dependency parsing are two different approaches to representing the syntactic structure of sentences. Constituency parsing provides a hierarchical, phrasal structure, while dependency parsing focuses on word-to-word relationships. The choice between them depends on the specific NLP task and the type of linguistic information needed. Both are fundamental for understanding and processing natural language text.</p>
<p><a href="https://corenlp.run/">Core NLP Run</a></p>
<p><img src="images/const.png" class="img-fluid"> <img src="images/depen.png" class="img-fluid"></p>
</section>
<section id="semantic-parsing" class="level3">
<h3 class="anchored" data-anchor-id="semantic-parsing">Semantic Parsing</h3>
<p>Semantic parsing is a natural language processing (NLP) task that involves mapping natural language expressions to a structured, formal representation of their meaning. This structured representation can be in the form of logical forms, knowledge graphs, or programming code, depending on the specific application. Semantic parsing is crucial in various NLP applications, and it plays a vital role in natural language understanding and human-computer interaction.</p>
<p>At the core of many semantic parsing systems are grammar rules that define how to parse natural language sentences. These rules describe the syntax of the language and the structure of sentences. For example, a basic grammar rule might specify that a “flight” query consists of a “from” location, a “to” location, and optionally, a “with” clause for additional conditions.</p>
<p>For example, find flights from new york to london for tomorrow,</p>
<p>maps to a structured representation like:</p>
<pre><code>(query
  (from new york)
  (to london)
  (on tomorrow))</code></pre>
<p><strong>Different Datasets</strong>: There are several datasets commonly used in semantic parsing research. Each dataset serves a specific purpose and has its own characteristics. Some notable ones include:</p>
<ol type="1">
<li><p><strong>ATIS (Airline Travel Information System)</strong>: This dataset is used for training and evaluating semantic parsers in the context of airline booking and travel information. It contains queries about flights, reservations, and related information.</p></li>
<li><p><strong>GeoQuery</strong>: GeoQuery focuses on querying a geographic database using natural language. It includes questions about geographical locations, distances, and related queries.</p></li>
<li><p><strong>Spider</strong>: The Spider dataset is designed for complex SQL query generation from natural language questions. It is particularly challenging because it involves understanding complex database structures and generating precise SQL queries.</p></li>
<li><p><strong>SCAN</strong>: The SCAN dataset involves language-based navigation tasks where a model must interpret natural language instructions to navigate through grid-like environments.</p></li>
<li><p><strong>WikiSQL</strong>: This dataset contains questions about relational databases, requiring systems to generate SQL queries that extract information from a given database.</p></li>
</ol>
<p>Examples</p>
<ol type="1">
<li><p><strong>Chatbots and Virtual Assistants</strong>: Virtual assistants like Siri and Alexa rely on semantic parsing to comprehend user commands and execute actions.</p></li>
<li><p><strong>Data Analysis</strong>: Semantic parsing is used in tools for data analysis, where users can describe complex queries in natural language to extract insights from large datasets.</p></li>
<li><p><strong>Programming Assistants</strong>: Developers can use semantic parsing to write code more efficiently by describing their intent in natural language, and the system generates the corresponding code.</p></li>
</ol>
<p><strong>Challenges</strong>: Semantic parsing is a challenging task for several reasons:</p>
<ol type="1">
<li><strong>Ambiguity</strong>: Natural language is often ambiguous, and a single sentence can have multiple valid interpretations. Semantic parsers need to disambiguate and select the correct interpretation.</li>
</ol>
<p>Ambiguous Natural Language Query: “Find flights from New York to Chicago with a stopover.”</p>
<p>The ambiguity here lies in the term “with a stopover.” It could be interpreted in different ways:</p>
<pre><code>The user is looking for flights that have a stopover (a connecting flight) during the journey.
The user is looking for direct flights from New York to Chicago, and the phrase "with a stopover" is providing additional information about the type of flight (e.g., the user prefers flights with a stopover).</code></pre>
<p>Semantic parsing aims to disambiguate such queries and convert them into a structured representation, which can then be further used to retrieve relevant information from a database or perform an action, like generating an SQL query.</p>
<ol type="1">
<li><p><strong>Variability</strong>: People express the same ideas in different ways, making it difficult to create comprehensive training datasets that cover all possible phrasings.</p></li>
<li><p><strong>Domain-specific Knowledge</strong>: Some semantic parsing tasks require domain-specific knowledge, which may not be readily available in training data.</p></li>
<li><p><strong>Compositionality</strong>: Many queries involve compositional meaning, where the meaning of the whole is determined by the meanings of its parts. Understanding how words and phrases combine is a complex task.</p></li>
</ol>
<p>semantic parsing is important in bridging the gap between natural language and structured data, but it remains a challenging problem due to the complexities and nuances of human language. Researchers continue to work on improving semantic parsing techniques to make them more accurate and versatile.</p>
</section>
<section id="machine-translation" class="level3">
<h3 class="anchored" data-anchor-id="machine-translation">Machine Translation</h3>
<p>There is no need for explanation, but one thing were focus is more on Multilingual MT.</p>
<p>We came a long way from rule-based and statistical approaches to cutting-edge Neural Networks. And above problems have shaped the world of NLP.</p>
</section>
</section>
<section id="thank-you" class="level2">
<h2 class="anchored" data-anchor-id="thank-you">Thank you</h2>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/aman5319\.github\.io\/portfolio\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aman5319/portfolio" data-repo-id="R_kgDOJ44pkw" data-category="Q&amp;A" data-category-id="DIC_kwDOJ44pk84CXwVt" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Blog made with 💜 and <a href="https://quarto.org/">Quarto</a>, by Aman Pandey. License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/aman5319/portfolio/blob/main/tech_blogs/NLP/nlp_overview.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/aman5319/portfolio/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:amanpandey@mailfence.com">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>